{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import copy\n",
    "from importlib import reload\n",
    "\n",
    "import torchvision\n",
    "import os\n",
    "from PIL import Image\n",
    "from torch.optim.lr_scheduler import StepLR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.001"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "1e-3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "from constants import csv_file, directory, INPUT_SHAPE, YEAR, ext\n",
    "\n",
    "from utils import Dataset_Diabetic, data_class\n",
    "\n",
    "from utils import (\n",
    "    plot_samples,\n",
    "    get_dataloader,\n",
    "    plot_confusion_matrix,\n",
    "    calculate_confusion_matrix,\n",
    "    accuracy_fn,\n",
    "    accuracy_sickness,\n",
    "    get_accuracies,\n",
    "    sample_iid,\n",
    ")\n",
    "\n",
    "from model import train_loop\n",
    "from model import Model_Retinopathy, validate\n",
    "\n",
    "from constants import EPOCHS, BATCH_SIZE, LEARNING_RATE, UPDATES\n",
    "from constants import K_CLIENTS, C, rounds, clients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# MODEL STUFF\n",
    "global_model = Model_Retinopathy().to(device)\n",
    "models_ind = [Model_Retinopathy().to(device) for _ in range(K_CLIENTS)]\n",
    "models_fed = [Model_Retinopathy().to(device) for _ in range(K_CLIENTS)]\n",
    "\n",
    "for model in models_ind:\n",
    "    model.set_weights(global_model.get_weights())\n",
    "for model in models_fed:\n",
    "    model.set_weights(global_model.get_weights())\n",
    "\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "# Best loss function when talking about multi-class classification\n",
    "optimizer = torch.optim.Adam(global_model.parameters(), lr=LEARNING_RATE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DATA STUFF\n",
    "df = pd.read_csv(csv_file)\n",
    "\n",
    "val_df = sample_iid(df, 0.05)\n",
    "df = df.drop(val_df.index)\n",
    "val_df = val_df.reset_index(drop=True)\n",
    "\n",
    "df = sample_iid(df, 0.5).reset_index(drop=True)\n",
    "\n",
    "samples = df.shape[0] // K_CLIENTS\n",
    "train_df = []\n",
    "\n",
    "while len(train_df) < K_CLIENTS - 1:\n",
    "    df_sample = df.sample(n=samples)\n",
    "    df.drop(df_sample.index, inplace=True)\n",
    "    train_df.append(df_sample.reset_index(drop=True))\n",
    "train_df.append(df.reset_index(drop=True))\n",
    "\n",
    "datasets, loaders = [], []\n",
    "for train_df_i in train_df:\n",
    "    data, loader = get_dataloader(train_df_i, ext, directory, BATCH_SIZE, True)\n",
    "    datasets.append(data)\n",
    "    loaders.append(loader)\n",
    "\n",
    "val_data, val_loader = get_dataloader(val_df, ext, directory, BATCH_SIZE, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "losses = []\n",
    "accuracies = []\n",
    "losses_clients = [[] for _ in range(K_CLIENTS)]\n",
    "accuracies_clients = [[] for _ in range(K_CLIENTS)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_accuracies():\n",
    "    fig, ax = plt.subplots()\n",
    "    for i in range(K_CLIENTS):\n",
    "        ax.plot(accuracies_clients[i], \"o-\")\n",
    "    ax.plot(accuracies, \"-\", label=\"Global\", linewidth=5, color=\"blue\")\n",
    "    ax.set_title(f\"Accuracies comparison, {K_CLIENTS} clients\")\n",
    "    ax.set_xlabel(\"Rounds\")\n",
    "    ax.set_ylabel(\"Accuracy\")\n",
    "    ax.legend()\n",
    "    return ax\n",
    "\n",
    "\n",
    "def plot_losses():\n",
    "    fig, ax = plt.subplots()\n",
    "    for i in range(K_CLIENTS):\n",
    "        ax.plot(losses_clients[i], \"o-\")\n",
    "    ax.plot(losses, \"-\", label=\"Global Loss\", linewidth=5, color=\"blue\")\n",
    "    ax.set_title(f\"Losses comparison, {K_CLIENTS} clients\")\n",
    "    ax.set_xlabel(\"Rounds\")\n",
    "    ax.set_ylabel(\"Loss\")\n",
    "    ax.legend()\n",
    "    return ax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_plots():\n",
    "    plt.ioff()\n",
    "\n",
    "    ax = plot_losses()\n",
    "    plt.savefig(\"Losses_fed.png\")\n",
    "    plt.close()\n",
    "\n",
    "    ax = plot_accuracies()\n",
    "    plt.savefig(\"Accuracies_fed.png\")\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fed_avg():\n",
    "    m_clients = int(max(1, K_CLIENTS * C))\n",
    "    for t in range(rounds):\n",
    "        print(\"ROUND: \", t)\n",
    "        print(\"-------------------------------\" * 3)\n",
    "        weight_global = global_model.get_weights()\n",
    "        selected_clients = np.random.choice(clients, m_clients, replace=False)\n",
    "        selected_clients.sort()\n",
    "\n",
    "        weights = [0] * K_CLIENTS\n",
    "        m_t = sum([len(datasets[i]) for i in selected_clients])\n",
    "        for client in selected_clients:\n",
    "            local_model = Model_Retinopathy().to(device)\n",
    "            local_model.set_weights(global_model.get_weights())\n",
    "\n",
    "            print(\"TRAINING CLIENT\", client, \"Federated\")\n",
    "            train_loop(\n",
    "                local_model,\n",
    "                loaders[client],\n",
    "                val_loader,\n",
    "                epochs=EPOCHS,\n",
    "                lr=LEARNING_RATE,\n",
    "                verbose=False,\n",
    "            )\n",
    "            print(\"TRAINING CLIENT\", client, \"Independent\")\n",
    "            train_loop(\n",
    "                models_ind[client],\n",
    "                loaders[client],\n",
    "                val_loader,\n",
    "                epochs=EPOCHS,\n",
    "                lr=LEARNING_RATE,\n",
    "                verbose=False,\n",
    "            )\n",
    "            weights[client] = local_model.get_weights()\n",
    "            for layer in weights[client]:\n",
    "                weights[client][layer] = (\n",
    "                    weights[client][layer] * len(datasets[client]) / m_t\n",
    "                )\n",
    "            losses_clients[client].append(models_ind[client].get_loss(val_loader))\n",
    "            accuracies_clients[client].append(\n",
    "                models_ind[client].get_accuracy(val_loader)\n",
    "            )\n",
    "        for layer in weight_global:\n",
    "            for i, client in enumerate(selected_clients):\n",
    "                if i == 0:\n",
    "                    weight_global[layer] = weights[client][layer]\n",
    "                else:\n",
    "                    weight_global[layer] = weights[client][layer] + weight_global[layer]\n",
    "        global_model.set_weights(weight_global)\n",
    "        loss = global_model.get_loss(val_loader)\n",
    "        losses.append(loss)\n",
    "        acc = global_model.get_accuracy(val_loader)\n",
    "        accuracies.append(acc)\n",
    "        print(f\"Loss = {loss}, Acc = {acc}\")\n",
    "\n",
    "        save_plots()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fed_avg()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.optim import Optimizer\n",
    "\n",
    "\n",
    "class ScaffoldOptimizer(Optimizer):\n",
    "    def __init__(self, params, lr, weight_decay):\n",
    "        defaults = dict(lr=lr)\n",
    "        super(ScaffoldOptimizer, self).__init__(params, defaults)\n",
    "\n",
    "    def step(self, server_controls, client_controls, closure=None):\n",
    "\n",
    "        loss = None\n",
    "        if closure is not None:\n",
    "            loss = closure\n",
    "\n",
    "        for group in self.param_groups:\n",
    "            for p, c, ci in zip(\n",
    "                group[\"params\"], server_controls.values(), client_controls.values()\n",
    "            ):\n",
    "                if p.grad is None:\n",
    "                    continue\n",
    "                ## IMPLEMENT ADAM TO THIS CRAP\n",
    "                dp = p.grad.data + c.data - ci.data\n",
    "                p.data = p.data - dp.data * group[\"lr\"]\n",
    "\n",
    "        return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initializing control variables\n",
    "for key, layer in global_model.named_parameters():\n",
    "    global_model.control[key] = torch.zeros_like(layer.data)\n",
    "    global_model.delta_control[key] = torch.zeros_like(layer.data)\n",
    "    global_model.delta_y[key] = torch.zeros_like(layer.data)\n",
    "for model in models_fed:\n",
    "    for key, layer in model.named_parameters():\n",
    "        model.control[key] = torch.zeros_like(layer.data)\n",
    "        model.delta_control[key] = torch.zeros_like(layer.data)\n",
    "        model.delta_y[key] = torch.zeros_like(layer.data)\n",
    "for model in models_ind:\n",
    "    for key, layer in model.named_parameters():\n",
    "        model.control[key] = torch.zeros_like(layer.data)\n",
    "        model.delta_control[key] = torch.zeros_like(layer.data)\n",
    "        model.delta_y[key] = torch.zeros_like(layer.data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss = 1.6919012069702148, Acc = 0.10382513661202186\n",
      "ROUND: 0\n",
      "--------------------------------------------------\n",
      "TRAINING CLIENT 0\n",
      "Validation Accuracy:  0.3934\n",
      "Validation Loss:  1.5832\n",
      "Validation Accuracy:  0.4918\n",
      "Validation Loss:  1.4556\n",
      "Validation Accuracy:  0.4918\n",
      "Validation Loss:  1.3290\n",
      "Validation Accuracy:  0.4918\n",
      "Validation Loss:  1.2720\n",
      "Validation Accuracy:  0.4918\n",
      "Validation Loss:  1.2106\n",
      "Validation Accuracy:  0.4918\n",
      "Validation Loss:  1.2056\n",
      "Validation Accuracy:  0.4918\n",
      "Validation Loss:  1.1475\n",
      "Validation Accuracy:  0.5027\n",
      "Validation Loss:  1.1455\n",
      "TRAINING INDEPENDENT...\n",
      "Validation Accuracy:  0.3880\n",
      "Validation Loss:  1.5683\n",
      "Validation Accuracy:  0.4863\n",
      "Validation Loss:  1.4407\n",
      "Validation Accuracy:  0.4918\n",
      "Validation Loss:  1.3554\n",
      "Validation Accuracy:  0.4918\n",
      "Validation Loss:  1.2735\n",
      "Validation Accuracy:  0.4918\n",
      "Validation Loss:  1.2355\n",
      "Validation Accuracy:  0.4918\n",
      "Validation Loss:  1.2005\n",
      "Validation Accuracy:  0.4918\n",
      "Validation Loss:  1.1644\n",
      "Validation Accuracy:  0.4973\n",
      "Validation Loss:  1.1622\n",
      "TRAINING CLIENT 1\n",
      "Validation Accuracy:  0.3770\n",
      "Validation Loss:  1.5916\n",
      "Validation Accuracy:  0.4863\n",
      "Validation Loss:  1.4744\n",
      "Validation Accuracy:  0.4918\n",
      "Validation Loss:  1.3875\n",
      "Validation Accuracy:  0.4918\n",
      "Validation Loss:  1.3199\n",
      "Validation Accuracy:  0.4918\n",
      "Validation Loss:  1.2820\n",
      "Validation Accuracy:  0.4918\n",
      "Validation Loss:  1.2311\n",
      "Validation Accuracy:  0.4918\n",
      "Validation Loss:  1.1933\n",
      "Validation Accuracy:  0.4918\n",
      "Validation Loss:  1.1704\n",
      "TRAINING INDEPENDENT...\n",
      "Validation Accuracy:  0.3989\n",
      "Validation Loss:  1.5841\n",
      "Validation Accuracy:  0.4863\n",
      "Validation Loss:  1.4731\n",
      "Validation Accuracy:  0.4918\n",
      "Validation Loss:  1.3727\n",
      "Validation Accuracy:  0.4918\n",
      "Validation Loss:  1.3148\n",
      "Validation Accuracy:  0.4918\n",
      "Validation Loss:  1.2658\n",
      "Validation Accuracy:  0.4918\n",
      "Validation Loss:  1.2451\n",
      "Validation Accuracy:  0.4918\n",
      "Validation Loss:  1.2109\n",
      "Validation Accuracy:  0.4918\n",
      "Validation Loss:  1.1727\n",
      "TRAINING CLIENT 2\n",
      "Validation Accuracy:  0.3716\n",
      "Validation Loss:  1.5865\n",
      "Validation Accuracy:  0.4918\n",
      "Validation Loss:  1.4771\n",
      "Validation Accuracy:  0.4863\n",
      "Validation Loss:  1.3817\n",
      "Validation Accuracy:  0.4918\n",
      "Validation Loss:  1.3168\n",
      "Validation Accuracy:  0.4973\n",
      "Validation Loss:  1.2719\n",
      "Validation Accuracy:  0.4973\n",
      "Validation Loss:  1.2258\n",
      "Validation Accuracy:  0.5027\n",
      "Validation Loss:  1.1856\n",
      "Validation Accuracy:  0.5027\n",
      "Validation Loss:  1.1555\n",
      "TRAINING INDEPENDENT...\n",
      "Validation Accuracy:  0.3552\n",
      "Validation Loss:  1.5929\n",
      "Validation Accuracy:  0.4918\n",
      "Validation Loss:  1.4739\n",
      "Validation Accuracy:  0.4809\n",
      "Validation Loss:  1.3825\n",
      "Validation Accuracy:  0.4918\n",
      "Validation Loss:  1.3016\n",
      "Validation Accuracy:  0.4973\n",
      "Validation Loss:  1.2802\n",
      "Validation Accuracy:  0.4973\n",
      "Validation Loss:  1.2285\n",
      "Validation Accuracy:  0.4973\n",
      "Validation Loss:  1.2082\n",
      "Validation Accuracy:  0.5082\n",
      "Validation Loss:  1.1624\n",
      "TRAINING CLIENT 3\n",
      "Validation Accuracy:  0.3716\n",
      "Validation Loss:  1.5899\n",
      "Validation Accuracy:  0.4863\n",
      "Validation Loss:  1.4853\n",
      "Validation Accuracy:  0.4809\n",
      "Validation Loss:  1.3976\n",
      "Validation Accuracy:  0.4918\n",
      "Validation Loss:  1.3240\n",
      "Validation Accuracy:  0.4918\n",
      "Validation Loss:  1.2812\n",
      "Validation Accuracy:  0.4973\n",
      "Validation Loss:  1.2327\n",
      "Validation Accuracy:  0.4973\n",
      "Validation Loss:  1.2047\n",
      "Validation Accuracy:  0.5082\n",
      "Validation Loss:  1.1668\n",
      "TRAINING INDEPENDENT...\n",
      "Validation Accuracy:  0.3607\n",
      "Validation Loss:  1.5991\n",
      "Validation Accuracy:  0.4918\n",
      "Validation Loss:  1.4964\n",
      "Validation Accuracy:  0.4809\n",
      "Validation Loss:  1.4013\n",
      "Validation Accuracy:  0.4918\n",
      "Validation Loss:  1.3124\n",
      "Validation Accuracy:  0.4918\n",
      "Validation Loss:  1.2746\n",
      "Validation Accuracy:  0.4973\n",
      "Validation Loss:  1.2342\n",
      "Validation Accuracy:  0.4973\n",
      "Validation Loss:  1.2123\n",
      "Validation Accuracy:  0.5027\n",
      "Validation Loss:  1.1837\n",
      "TRAINING CLIENT 4\n",
      "Validation Accuracy:  0.3825\n",
      "Validation Loss:  1.5774\n",
      "Validation Accuracy:  0.4809\n",
      "Validation Loss:  1.4649\n",
      "Validation Accuracy:  0.4809\n",
      "Validation Loss:  1.3674\n",
      "Validation Accuracy:  0.4973\n",
      "Validation Loss:  1.3026\n",
      "Validation Accuracy:  0.4973\n",
      "Validation Loss:  1.2450\n",
      "Validation Accuracy:  0.4973\n",
      "Validation Loss:  1.2314\n",
      "Validation Accuracy:  0.5027\n",
      "Validation Loss:  1.1767\n",
      "Validation Accuracy:  0.5137\n",
      "Validation Loss:  1.1640\n",
      "TRAINING INDEPENDENT...\n",
      "Validation Accuracy:  0.3770\n",
      "Validation Loss:  1.5767\n",
      "Validation Accuracy:  0.4863\n",
      "Validation Loss:  1.4625\n",
      "Validation Accuracy:  0.4918\n",
      "Validation Loss:  1.3663\n",
      "Validation Accuracy:  0.4973\n",
      "Validation Loss:  1.2919\n",
      "Validation Accuracy:  0.4973\n",
      "Validation Loss:  1.2655\n",
      "Validation Accuracy:  0.5027\n",
      "Validation Loss:  1.2051\n",
      "Validation Accuracy:  0.5027\n",
      "Validation Loss:  1.1809\n",
      "Validation Accuracy:  0.5355\n",
      "Validation Loss:  1.1650\n",
      "TRAINING CLIENT 5\n",
      "Validation Accuracy:  0.3934\n",
      "Validation Loss:  1.5856\n",
      "Validation Accuracy:  0.4863\n",
      "Validation Loss:  1.4721\n",
      "Validation Accuracy:  0.4918\n",
      "Validation Loss:  1.3900\n",
      "Validation Accuracy:  0.4809\n",
      "Validation Loss:  1.3270\n",
      "Validation Accuracy:  0.4973\n",
      "Validation Loss:  1.2843\n",
      "Validation Accuracy:  0.5082\n",
      "Validation Loss:  1.2437\n",
      "Validation Accuracy:  0.5137\n",
      "Validation Loss:  1.2073\n",
      "Validation Accuracy:  0.5410\n",
      "Validation Loss:  1.1838\n",
      "TRAINING INDEPENDENT...\n",
      "Validation Accuracy:  0.3661\n",
      "Validation Loss:  1.5735\n",
      "Validation Accuracy:  0.4863\n",
      "Validation Loss:  1.4823\n",
      "Validation Accuracy:  0.4918\n",
      "Validation Loss:  1.3997\n",
      "Validation Accuracy:  0.4918\n",
      "Validation Loss:  1.3436\n",
      "Validation Accuracy:  0.4973\n",
      "Validation Loss:  1.2887\n",
      "Validation Accuracy:  0.5027\n",
      "Validation Loss:  1.2479\n",
      "Validation Accuracy:  0.5137\n",
      "Validation Loss:  1.2125\n",
      "Validation Accuracy:  0.5410\n",
      "Validation Loss:  1.1844\n",
      "TRAINING CLIENT 6\n",
      "Validation Accuracy:  0.3934\n",
      "Validation Loss:  1.5794\n",
      "Validation Accuracy:  0.4863\n",
      "Validation Loss:  1.4610\n",
      "Validation Accuracy:  0.4918\n",
      "Validation Loss:  1.3562\n",
      "Validation Accuracy:  0.4918\n",
      "Validation Loss:  1.2949\n",
      "Validation Accuracy:  0.4918\n",
      "Validation Loss:  1.2469\n",
      "Validation Accuracy:  0.4918\n",
      "Validation Loss:  1.2075\n",
      "Validation Accuracy:  0.4973\n",
      "Validation Loss:  1.1901\n",
      "Validation Accuracy:  0.4973\n",
      "Validation Loss:  1.1613\n",
      "TRAINING INDEPENDENT...\n",
      "Validation Accuracy:  0.3825\n",
      "Validation Loss:  1.5678\n",
      "Validation Accuracy:  0.4863\n",
      "Validation Loss:  1.4571\n",
      "Validation Accuracy:  0.4863\n",
      "Validation Loss:  1.3591\n",
      "Validation Accuracy:  0.4918\n",
      "Validation Loss:  1.2924\n",
      "Validation Accuracy:  0.4918\n",
      "Validation Loss:  1.2367\n",
      "Validation Accuracy:  0.4918\n",
      "Validation Loss:  1.1989\n",
      "Validation Accuracy:  0.4973\n",
      "Validation Loss:  1.1759\n",
      "Validation Accuracy:  0.4973\n",
      "Validation Loss:  1.1413\n",
      "TRAINING CLIENT 7\n",
      "Validation Accuracy:  0.3607\n",
      "Validation Loss:  1.5967\n",
      "Validation Accuracy:  0.4863\n",
      "Validation Loss:  1.4913\n",
      "Validation Accuracy:  0.4918\n",
      "Validation Loss:  1.4139\n",
      "Validation Accuracy:  0.4918\n",
      "Validation Loss:  1.3431\n",
      "Validation Accuracy:  0.4918\n",
      "Validation Loss:  1.3051\n",
      "Validation Accuracy:  0.4918\n",
      "Validation Loss:  1.2718\n",
      "Validation Accuracy:  0.4973\n",
      "Validation Loss:  1.2033\n",
      "Validation Accuracy:  0.4973\n",
      "Validation Loss:  1.1994\n",
      "TRAINING INDEPENDENT...\n",
      "Validation Accuracy:  0.3552\n",
      "Validation Loss:  1.6037\n",
      "Validation Accuracy:  0.4863\n",
      "Validation Loss:  1.4839\n",
      "Validation Accuracy:  0.4863\n",
      "Validation Loss:  1.4109\n",
      "Validation Accuracy:  0.4918\n",
      "Validation Loss:  1.3523\n",
      "Validation Accuracy:  0.4918\n",
      "Validation Loss:  1.2845\n",
      "Validation Accuracy:  0.4918\n",
      "Validation Loss:  1.2691\n",
      "Validation Accuracy:  0.4973\n",
      "Validation Loss:  1.2411\n",
      "Validation Accuracy:  0.4973\n",
      "Validation Loss:  1.1907\n",
      "TRAINING CLIENT 8\n",
      "Validation Accuracy:  0.3770\n",
      "Validation Loss:  1.5884\n",
      "Validation Accuracy:  0.4809\n",
      "Validation Loss:  1.4853\n",
      "Validation Accuracy:  0.4863\n",
      "Validation Loss:  1.3812\n",
      "Validation Accuracy:  0.4918\n",
      "Validation Loss:  1.3143\n",
      "Validation Accuracy:  0.4918\n",
      "Validation Loss:  1.2626\n",
      "Validation Accuracy:  0.4918\n",
      "Validation Loss:  1.2297\n",
      "Validation Accuracy:  0.4973\n",
      "Validation Loss:  1.1959\n",
      "Validation Accuracy:  0.5027\n",
      "Validation Loss:  1.1772\n",
      "TRAINING INDEPENDENT...\n",
      "Validation Accuracy:  0.3825\n",
      "Validation Loss:  1.5852\n",
      "Validation Accuracy:  0.4809\n",
      "Validation Loss:  1.4680\n",
      "Validation Accuracy:  0.4863\n",
      "Validation Loss:  1.3986\n",
      "Validation Accuracy:  0.4918\n",
      "Validation Loss:  1.3205\n",
      "Validation Accuracy:  0.4918\n",
      "Validation Loss:  1.2797\n",
      "Validation Accuracy:  0.4918\n",
      "Validation Loss:  1.2373\n",
      "Validation Accuracy:  0.4918\n",
      "Validation Loss:  1.1949\n",
      "Validation Accuracy:  0.4973\n",
      "Validation Loss:  1.1717\n",
      "TRAINING CLIENT 9\n",
      "Validation Accuracy:  0.3934\n",
      "Validation Loss:  1.5785\n",
      "Validation Accuracy:  0.4863\n",
      "Validation Loss:  1.4595\n",
      "Validation Accuracy:  0.4918\n",
      "Validation Loss:  1.3616\n",
      "Validation Accuracy:  0.4973\n",
      "Validation Loss:  1.2952\n",
      "Validation Accuracy:  0.4918\n",
      "Validation Loss:  1.2534\n",
      "Validation Accuracy:  0.5301\n",
      "Validation Loss:  1.2077\n",
      "Validation Accuracy:  0.5956\n",
      "Validation Loss:  1.1825\n",
      "Validation Accuracy:  0.6120\n",
      "Validation Loss:  1.1689\n",
      "TRAINING INDEPENDENT...\n",
      "Validation Accuracy:  0.3934\n",
      "Validation Loss:  1.5785\n",
      "Validation Accuracy:  0.4863\n",
      "Validation Loss:  1.4662\n",
      "Validation Accuracy:  0.4918\n",
      "Validation Loss:  1.3471\n",
      "Validation Accuracy:  0.4973\n",
      "Validation Loss:  1.2894\n",
      "Validation Accuracy:  0.4973\n",
      "Validation Loss:  1.2472\n",
      "Validation Accuracy:  0.5137\n",
      "Validation Loss:  1.2158\n",
      "Validation Accuracy:  0.5628\n",
      "Validation Loss:  1.1704\n",
      "Validation Accuracy:  0.6175\n",
      "Validation Loss:  1.1580\n",
      "Loss = 1.286314641435941, Acc = 0.4918032786885246\n",
      "ROUND: 1\n",
      "--------------------------------------------------\n",
      "TRAINING CLIENT 0\n",
      "Validation Accuracy:  0.5082\n",
      "Validation Loss:  1.1332\n",
      "Validation Accuracy:  0.5410\n",
      "Validation Loss:  1.1037\n",
      "Validation Accuracy:  0.5738\n",
      "Validation Loss:  1.0826\n",
      "Validation Accuracy:  0.5902\n",
      "Validation Loss:  1.0536\n",
      "Validation Accuracy:  0.6230\n",
      "Validation Loss:  1.0438\n",
      "Validation Accuracy:  0.6339\n",
      "Validation Loss:  1.0242\n",
      "Validation Accuracy:  0.6612\n",
      "Validation Loss:  1.0105\n",
      "Validation Accuracy:  0.6667\n",
      "Validation Loss:  0.9855\n",
      "TRAINING INDEPENDENT...\n",
      "Validation Accuracy:  0.5027\n",
      "Validation Loss:  1.1096\n",
      "Validation Accuracy:  0.5246\n",
      "Validation Loss:  1.0830\n",
      "Validation Accuracy:  0.5574\n",
      "Validation Loss:  1.0976\n",
      "Validation Accuracy:  0.5683\n",
      "Validation Loss:  1.0400\n",
      "Validation Accuracy:  0.5902\n",
      "Validation Loss:  1.0127\n",
      "Validation Accuracy:  0.6339\n",
      "Validation Loss:  1.0174\n",
      "Validation Accuracy:  0.6557\n",
      "Validation Loss:  0.9961\n",
      "Validation Accuracy:  0.6776\n",
      "Validation Loss:  1.0065\n",
      "TRAINING CLIENT 1\n",
      "Validation Accuracy:  0.5027\n",
      "Validation Loss:  1.1376\n",
      "Validation Accuracy:  0.5191\n",
      "Validation Loss:  1.1060\n",
      "Validation Accuracy:  0.5246\n",
      "Validation Loss:  1.0910\n",
      "Validation Accuracy:  0.5738\n",
      "Validation Loss:  1.0730\n",
      "Validation Accuracy:  0.6011\n",
      "Validation Loss:  1.0675\n",
      "Validation Accuracy:  0.6120\n",
      "Validation Loss:  1.0376\n",
      "Validation Accuracy:  0.6175\n",
      "Validation Loss:  1.0198\n",
      "Validation Accuracy:  0.6339\n",
      "Validation Loss:  1.0078\n",
      "TRAINING INDEPENDENT...\n",
      "Validation Accuracy:  0.4918\n",
      "Validation Loss:  1.1478\n",
      "Validation Accuracy:  0.4918\n",
      "Validation Loss:  1.1391\n",
      "Validation Accuracy:  0.4973\n",
      "Validation Loss:  1.1237\n",
      "Validation Accuracy:  0.4973\n",
      "Validation Loss:  1.0869\n",
      "Validation Accuracy:  0.5191\n",
      "Validation Loss:  1.0895\n",
      "Validation Accuracy:  0.5410\n",
      "Validation Loss:  1.0593\n",
      "Validation Accuracy:  0.6066\n",
      "Validation Loss:  1.0416\n",
      "Validation Accuracy:  0.6120\n",
      "Validation Loss:  1.0336\n",
      "TRAINING CLIENT 2\n",
      "Validation Accuracy:  0.5191\n",
      "Validation Loss:  1.1409\n",
      "Validation Accuracy:  0.5574\n",
      "Validation Loss:  1.1327\n",
      "Validation Accuracy:  0.6066\n",
      "Validation Loss:  1.0998\n",
      "Validation Accuracy:  0.6448\n",
      "Validation Loss:  1.0756\n",
      "Validation Accuracy:  0.6612\n",
      "Validation Loss:  1.0445\n",
      "Validation Accuracy:  0.6612\n",
      "Validation Loss:  1.0282\n",
      "Validation Accuracy:  0.6776\n",
      "Validation Loss:  1.0086\n",
      "Validation Accuracy:  0.6940\n",
      "Validation Loss:  1.0155\n",
      "TRAINING INDEPENDENT...\n",
      "Validation Accuracy:  0.5191\n",
      "Validation Loss:  1.1450\n",
      "Validation Accuracy:  0.5738\n",
      "Validation Loss:  1.1297\n",
      "Validation Accuracy:  0.6230\n",
      "Validation Loss:  1.1034\n",
      "Validation Accuracy:  0.6503\n",
      "Validation Loss:  1.0685\n",
      "Validation Accuracy:  0.6612\n",
      "Validation Loss:  1.0404\n",
      "Validation Accuracy:  0.6721\n",
      "Validation Loss:  1.0420\n",
      "Validation Accuracy:  0.6885\n",
      "Validation Loss:  1.0332\n",
      "Validation Accuracy:  0.6995\n",
      "Validation Loss:  1.0024\n",
      "TRAINING CLIENT 3\n",
      "Validation Accuracy:  0.5191\n",
      "Validation Loss:  1.1443\n",
      "Validation Accuracy:  0.5792\n",
      "Validation Loss:  1.1188\n",
      "Validation Accuracy:  0.6230\n",
      "Validation Loss:  1.0849\n",
      "Validation Accuracy:  0.6339\n",
      "Validation Loss:  1.0748\n",
      "Validation Accuracy:  0.6612\n",
      "Validation Loss:  1.0453\n",
      "Validation Accuracy:  0.6612\n",
      "Validation Loss:  1.0444\n",
      "Validation Accuracy:  0.6721\n",
      "Validation Loss:  1.0137\n",
      "Validation Accuracy:  0.6831\n",
      "Validation Loss:  0.9999\n",
      "TRAINING INDEPENDENT...\n",
      "Validation Accuracy:  0.5464\n",
      "Validation Loss:  1.1505\n",
      "Validation Accuracy:  0.5847\n",
      "Validation Loss:  1.1141\n",
      "Validation Accuracy:  0.6011\n",
      "Validation Loss:  1.1157\n",
      "Validation Accuracy:  0.6230\n",
      "Validation Loss:  1.0611\n",
      "Validation Accuracy:  0.6448\n",
      "Validation Loss:  1.0758\n",
      "Validation Accuracy:  0.6721\n",
      "Validation Loss:  1.0461\n",
      "Validation Accuracy:  0.6776\n",
      "Validation Loss:  1.0325\n",
      "Validation Accuracy:  0.6831\n",
      "Validation Loss:  1.0397\n",
      "TRAINING CLIENT 4\n",
      "Validation Accuracy:  0.5027\n",
      "Validation Loss:  1.1328\n",
      "Validation Accuracy:  0.5738\n",
      "Validation Loss:  1.1135\n",
      "Validation Accuracy:  0.6066\n",
      "Validation Loss:  1.0927\n",
      "Validation Accuracy:  0.6339\n",
      "Validation Loss:  1.0640\n",
      "Validation Accuracy:  0.6557\n",
      "Validation Loss:  1.0680\n",
      "Validation Accuracy:  0.6667\n",
      "Validation Loss:  1.0221\n",
      "Validation Accuracy:  0.6721\n",
      "Validation Loss:  1.0353\n",
      "Validation Accuracy:  0.6831\n",
      "Validation Loss:  1.0131\n",
      "TRAINING INDEPENDENT...\n",
      "Validation Accuracy:  0.5902\n",
      "Validation Loss:  1.1495\n",
      "Validation Accuracy:  0.6175\n",
      "Validation Loss:  1.0794\n",
      "Validation Accuracy:  0.6339\n",
      "Validation Loss:  1.1093\n",
      "Validation Accuracy:  0.6612\n",
      "Validation Loss:  1.0939\n",
      "Validation Accuracy:  0.6557\n",
      "Validation Loss:  1.0625\n",
      "Validation Accuracy:  0.6721\n",
      "Validation Loss:  1.0243\n",
      "Validation Accuracy:  0.6940\n",
      "Validation Loss:  1.0330\n",
      "Validation Accuracy:  0.6940\n",
      "Validation Loss:  1.0022\n",
      "TRAINING CLIENT 5\n",
      "Validation Accuracy:  0.5137\n",
      "Validation Loss:  1.1374\n",
      "Validation Accuracy:  0.5792\n",
      "Validation Loss:  1.1139\n",
      "Validation Accuracy:  0.6011\n",
      "Validation Loss:  1.0859\n",
      "Validation Accuracy:  0.6284\n",
      "Validation Loss:  1.0881\n",
      "Validation Accuracy:  0.6393\n",
      "Validation Loss:  1.0707\n",
      "Validation Accuracy:  0.6557\n",
      "Validation Loss:  1.0538\n",
      "Validation Accuracy:  0.6557\n",
      "Validation Loss:  1.0416\n",
      "Validation Accuracy:  0.6667\n",
      "Validation Loss:  1.0121\n",
      "TRAINING INDEPENDENT...\n",
      "Validation Accuracy:  0.5628\n",
      "Validation Loss:  1.1471\n",
      "Validation Accuracy:  0.6066\n",
      "Validation Loss:  1.1206\n",
      "Validation Accuracy:  0.6066\n",
      "Validation Loss:  1.1432\n",
      "Validation Accuracy:  0.6339\n",
      "Validation Loss:  1.0971\n",
      "Validation Accuracy:  0.6393\n",
      "Validation Loss:  1.1028\n",
      "Validation Accuracy:  0.6503\n",
      "Validation Loss:  1.0675\n",
      "Validation Accuracy:  0.6667\n",
      "Validation Loss:  1.0556\n",
      "Validation Accuracy:  0.6721\n",
      "Validation Loss:  1.0411\n",
      "TRAINING CLIENT 6\n",
      "Validation Accuracy:  0.5027\n",
      "Validation Loss:  1.1327\n",
      "Validation Accuracy:  0.5410\n",
      "Validation Loss:  1.0988\n",
      "Validation Accuracy:  0.5738\n",
      "Validation Loss:  1.0834\n",
      "Validation Accuracy:  0.6120\n",
      "Validation Loss:  1.0707\n",
      "Validation Accuracy:  0.6339\n",
      "Validation Loss:  1.0577\n",
      "Validation Accuracy:  0.6503\n",
      "Validation Loss:  1.0296\n",
      "Validation Accuracy:  0.6612\n",
      "Validation Loss:  1.0245\n",
      "Validation Accuracy:  0.6776\n",
      "Validation Loss:  0.9842\n",
      "TRAINING INDEPENDENT...\n",
      "Validation Accuracy:  0.5027\n",
      "Validation Loss:  1.1486\n",
      "Validation Accuracy:  0.5246\n",
      "Validation Loss:  1.1037\n",
      "Validation Accuracy:  0.5519\n",
      "Validation Loss:  1.0907\n",
      "Validation Accuracy:  0.5956\n",
      "Validation Loss:  1.0516\n",
      "Validation Accuracy:  0.6175\n",
      "Validation Loss:  1.0375\n",
      "Validation Accuracy:  0.6339\n",
      "Validation Loss:  1.0301\n",
      "Validation Accuracy:  0.6612\n",
      "Validation Loss:  1.0273\n",
      "Validation Accuracy:  0.6831\n",
      "Validation Loss:  0.9718\n",
      "TRAINING CLIENT 7\n",
      "Validation Accuracy:  0.5082\n",
      "Validation Loss:  1.1513\n",
      "Validation Accuracy:  0.5464\n",
      "Validation Loss:  1.1213\n",
      "Validation Accuracy:  0.5519\n",
      "Validation Loss:  1.0950\n",
      "Validation Accuracy:  0.5792\n",
      "Validation Loss:  1.0841\n",
      "Validation Accuracy:  0.5956\n",
      "Validation Loss:  1.0774\n",
      "Validation Accuracy:  0.6066\n",
      "Validation Loss:  1.0509\n",
      "Validation Accuracy:  0.6175\n",
      "Validation Loss:  1.0215\n",
      "Validation Accuracy:  0.6503\n",
      "Validation Loss:  1.0205\n",
      "TRAINING INDEPENDENT...\n",
      "Validation Accuracy:  0.4973\n",
      "Validation Loss:  1.1653\n",
      "Validation Accuracy:  0.5082\n",
      "Validation Loss:  1.1458\n",
      "Validation Accuracy:  0.5082\n",
      "Validation Loss:  1.1288\n",
      "Validation Accuracy:  0.5355\n",
      "Validation Loss:  1.1037\n",
      "Validation Accuracy:  0.5683\n",
      "Validation Loss:  1.0757\n",
      "Validation Accuracy:  0.5902\n",
      "Validation Loss:  1.0640\n",
      "Validation Accuracy:  0.6011\n",
      "Validation Loss:  1.0461\n",
      "Validation Accuracy:  0.6120\n",
      "Validation Loss:  1.0387\n",
      "TRAINING CLIENT 8\n",
      "Validation Accuracy:  0.5082\n",
      "Validation Loss:  1.1351\n",
      "Validation Accuracy:  0.5301\n",
      "Validation Loss:  1.1246\n",
      "Validation Accuracy:  0.5683\n",
      "Validation Loss:  1.0921\n",
      "Validation Accuracy:  0.6011\n",
      "Validation Loss:  1.0717\n",
      "Validation Accuracy:  0.6175\n",
      "Validation Loss:  1.0458\n",
      "Validation Accuracy:  0.6339\n",
      "Validation Loss:  1.0298\n",
      "Validation Accuracy:  0.6339\n",
      "Validation Loss:  1.0353\n",
      "Validation Accuracy:  0.6448\n",
      "Validation Loss:  1.0103\n",
      "TRAINING INDEPENDENT...\n",
      "Validation Accuracy:  0.5027\n",
      "Validation Loss:  1.1409\n",
      "Validation Accuracy:  0.5137\n",
      "Validation Loss:  1.1312\n",
      "Validation Accuracy:  0.5355\n",
      "Validation Loss:  1.0997\n",
      "Validation Accuracy:  0.5519\n",
      "Validation Loss:  1.0819\n",
      "Validation Accuracy:  0.5792\n",
      "Validation Loss:  1.0665\n",
      "Validation Accuracy:  0.6175\n",
      "Validation Loss:  1.0284\n",
      "Validation Accuracy:  0.6230\n",
      "Validation Loss:  1.0610\n",
      "Validation Accuracy:  0.6284\n",
      "Validation Loss:  0.9941\n",
      "TRAINING CLIENT 9\n",
      "Validation Accuracy:  0.5410\n",
      "Validation Loss:  1.1321\n",
      "Validation Accuracy:  0.5956\n",
      "Validation Loss:  1.0917\n",
      "Validation Accuracy:  0.6284\n",
      "Validation Loss:  1.0874\n",
      "Validation Accuracy:  0.6448\n",
      "Validation Loss:  1.0702\n",
      "Validation Accuracy:  0.6721\n",
      "Validation Loss:  1.0446\n",
      "Validation Accuracy:  0.6885\n",
      "Validation Loss:  1.0197\n",
      "Validation Accuracy:  0.6885\n",
      "Validation Loss:  1.0174\n",
      "Validation Accuracy:  0.6995\n",
      "Validation Loss:  0.9974\n",
      "TRAINING INDEPENDENT...\n",
      "Validation Accuracy:  0.6230\n",
      "Validation Loss:  1.1393\n",
      "Validation Accuracy:  0.6284\n",
      "Validation Loss:  1.1430\n",
      "Validation Accuracy:  0.6503\n",
      "Validation Loss:  1.0749\n",
      "Validation Accuracy:  0.6831\n",
      "Validation Loss:  1.0626\n",
      "Validation Accuracy:  0.6885\n",
      "Validation Loss:  1.0403\n",
      "Validation Accuracy:  0.6831\n",
      "Validation Loss:  1.0583\n",
      "Validation Accuracy:  0.6885\n",
      "Validation Loss:  1.0379\n",
      "Validation Accuracy:  0.6885\n",
      "Validation Loss:  1.0037\n",
      "Loss = 1.2706761757532756, Acc = 0.4918032786885246\n",
      "ROUND: 2\n",
      "--------------------------------------------------\n",
      "TRAINING CLIENT 0\n",
      "Validation Accuracy:  0.7049\n",
      "Validation Loss:  0.9783\n",
      "Validation Accuracy:  0.6885\n",
      "Validation Loss:  0.9555\n",
      "Validation Accuracy:  0.6940\n",
      "Validation Loss:  0.9383\n",
      "Validation Accuracy:  0.6831\n",
      "Validation Loss:  0.9402\n",
      "Validation Accuracy:  0.6995\n",
      "Validation Loss:  0.9217\n",
      "Validation Accuracy:  0.7104\n",
      "Validation Loss:  0.9190\n",
      "Validation Accuracy:  0.7104\n",
      "Validation Loss:  0.8904\n",
      "Validation Accuracy:  0.7158\n",
      "Validation Loss:  0.9017\n",
      "TRAINING INDEPENDENT...\n",
      "Validation Accuracy:  0.6885\n",
      "Validation Loss:  0.9645\n",
      "Validation Accuracy:  0.6885\n",
      "Validation Loss:  0.9687\n",
      "Validation Accuracy:  0.6885\n",
      "Validation Loss:  0.9976\n",
      "Validation Accuracy:  0.6885\n",
      "Validation Loss:  0.9372\n",
      "Validation Accuracy:  0.6940\n",
      "Validation Loss:  0.9488\n",
      "Validation Accuracy:  0.7104\n",
      "Validation Loss:  0.9192\n",
      "Validation Accuracy:  0.7104\n",
      "Validation Loss:  0.9184\n",
      "Validation Accuracy:  0.7104\n",
      "Validation Loss:  0.8945\n",
      "TRAINING CLIENT 1\n",
      "Validation Accuracy:  0.6776\n",
      "Validation Loss:  0.9949\n",
      "Validation Accuracy:  0.6831\n",
      "Validation Loss:  0.9727\n",
      "Validation Accuracy:  0.6831\n",
      "Validation Loss:  0.9752\n",
      "Validation Accuracy:  0.6831\n",
      "Validation Loss:  0.9403\n",
      "Validation Accuracy:  0.6831\n",
      "Validation Loss:  0.9601\n",
      "Validation Accuracy:  0.6831\n",
      "Validation Loss:  0.9443\n",
      "Validation Accuracy:  0.6940\n",
      "Validation Loss:  0.9175\n",
      "Validation Accuracy:  0.7049\n",
      "Validation Loss:  0.8980\n",
      "TRAINING INDEPENDENT...\n",
      "Validation Accuracy:  0.6120\n",
      "Validation Loss:  1.0041\n",
      "Validation Accuracy:  0.6175\n",
      "Validation Loss:  0.9971\n",
      "Validation Accuracy:  0.6284\n",
      "Validation Loss:  0.9823\n",
      "Validation Accuracy:  0.6612\n",
      "Validation Loss:  0.9790\n",
      "Validation Accuracy:  0.6721\n",
      "Validation Loss:  0.9671\n",
      "Validation Accuracy:  0.6721\n",
      "Validation Loss:  0.9599\n",
      "Validation Accuracy:  0.6940\n",
      "Validation Loss:  0.9318\n",
      "Validation Accuracy:  0.6940\n",
      "Validation Loss:  0.9199\n",
      "TRAINING CLIENT 2\n",
      "Validation Accuracy:  0.6831\n",
      "Validation Loss:  0.9834\n",
      "Validation Accuracy:  0.6940\n",
      "Validation Loss:  0.9718\n",
      "Validation Accuracy:  0.6885\n",
      "Validation Loss:  0.9517\n",
      "Validation Accuracy:  0.7049\n",
      "Validation Loss:  0.9697\n",
      "Validation Accuracy:  0.7049\n",
      "Validation Loss:  0.9491\n",
      "Validation Accuracy:  0.7049\n",
      "Validation Loss:  0.9707\n",
      "Validation Accuracy:  0.7104\n",
      "Validation Loss:  0.9271\n",
      "Validation Accuracy:  0.7104\n",
      "Validation Loss:  0.9263\n",
      "TRAINING INDEPENDENT...\n",
      "Validation Accuracy:  0.6995\n",
      "Validation Loss:  0.9899\n",
      "Validation Accuracy:  0.6995\n",
      "Validation Loss:  0.9913\n",
      "Validation Accuracy:  0.6995\n",
      "Validation Loss:  0.9525\n",
      "Validation Accuracy:  0.6995\n",
      "Validation Loss:  0.9786\n",
      "Validation Accuracy:  0.6995\n",
      "Validation Loss:  0.9430\n",
      "Validation Accuracy:  0.6995\n",
      "Validation Loss:  0.9581\n",
      "Validation Accuracy:  0.6940\n",
      "Validation Loss:  0.9559\n",
      "Validation Accuracy:  0.6995\n",
      "Validation Loss:  0.9277\n",
      "TRAINING CLIENT 3\n",
      "Validation Accuracy:  0.6885\n",
      "Validation Loss:  0.9972\n",
      "Validation Accuracy:  0.6831\n",
      "Validation Loss:  0.9948\n",
      "Validation Accuracy:  0.6995\n",
      "Validation Loss:  0.9715\n",
      "Validation Accuracy:  0.7049\n",
      "Validation Loss:  0.9442\n",
      "Validation Accuracy:  0.7049\n",
      "Validation Loss:  0.9343\n",
      "Validation Accuracy:  0.7049\n",
      "Validation Loss:  0.9272\n",
      "Validation Accuracy:  0.7104\n",
      "Validation Loss:  0.9197\n",
      "Validation Accuracy:  0.7104\n",
      "Validation Loss:  0.9217\n",
      "TRAINING INDEPENDENT...\n",
      "Validation Accuracy:  0.6885\n",
      "Validation Loss:  1.0012\n",
      "Validation Accuracy:  0.6940\n",
      "Validation Loss:  0.9921\n",
      "Validation Accuracy:  0.6940\n",
      "Validation Loss:  0.9644\n",
      "Validation Accuracy:  0.6940\n",
      "Validation Loss:  0.9805\n",
      "Validation Accuracy:  0.6940\n",
      "Validation Loss:  0.9785\n",
      "Validation Accuracy:  0.6940\n",
      "Validation Loss:  0.9479\n",
      "Validation Accuracy:  0.6995\n",
      "Validation Loss:  0.9432\n",
      "Validation Accuracy:  0.7049\n",
      "Validation Loss:  0.9348\n",
      "TRAINING CLIENT 4\n",
      "Validation Accuracy:  0.6776\n",
      "Validation Loss:  0.9924\n",
      "Validation Accuracy:  0.6940\n",
      "Validation Loss:  0.9867\n",
      "Validation Accuracy:  0.7049\n",
      "Validation Loss:  0.9572\n",
      "Validation Accuracy:  0.7104\n",
      "Validation Loss:  0.9620\n",
      "Validation Accuracy:  0.7104\n",
      "Validation Loss:  0.9430\n",
      "Validation Accuracy:  0.7104\n",
      "Validation Loss:  0.9363\n",
      "Validation Accuracy:  0.7104\n",
      "Validation Loss:  0.9035\n",
      "Validation Accuracy:  0.7049\n",
      "Validation Loss:  0.8993\n",
      "TRAINING INDEPENDENT...\n",
      "Validation Accuracy:  0.6940\n",
      "Validation Loss:  0.9772\n",
      "Validation Accuracy:  0.6995\n",
      "Validation Loss:  0.9692\n",
      "Validation Accuracy:  0.6995\n",
      "Validation Loss:  0.9457\n",
      "Validation Accuracy:  0.7104\n",
      "Validation Loss:  0.9743\n",
      "Validation Accuracy:  0.7049\n",
      "Validation Loss:  0.9478\n",
      "Validation Accuracy:  0.7049\n",
      "Validation Loss:  0.9403\n",
      "Validation Accuracy:  0.7049\n",
      "Validation Loss:  0.9135\n",
      "Validation Accuracy:  0.7049\n",
      "Validation Loss:  0.9159\n",
      "TRAINING CLIENT 5\n",
      "Validation Accuracy:  0.6776\n",
      "Validation Loss:  0.9975\n",
      "Validation Accuracy:  0.6831\n",
      "Validation Loss:  0.9623\n",
      "Validation Accuracy:  0.6995\n",
      "Validation Loss:  0.9697\n",
      "Validation Accuracy:  0.6940\n",
      "Validation Loss:  0.9784\n",
      "Validation Accuracy:  0.7049\n",
      "Validation Loss:  0.9544\n",
      "Validation Accuracy:  0.7104\n",
      "Validation Loss:  0.9454\n",
      "Validation Accuracy:  0.7049\n",
      "Validation Loss:  0.9238\n",
      "Validation Accuracy:  0.7049\n",
      "Validation Loss:  0.9084\n",
      "TRAINING INDEPENDENT...\n",
      "Validation Accuracy:  0.6721\n",
      "Validation Loss:  1.0402\n",
      "Validation Accuracy:  0.6885\n",
      "Validation Loss:  1.0161\n",
      "Validation Accuracy:  0.6831\n",
      "Validation Loss:  0.9825\n",
      "Validation Accuracy:  0.6995\n",
      "Validation Loss:  0.9785\n",
      "Validation Accuracy:  0.6995\n",
      "Validation Loss:  0.9992\n",
      "Validation Accuracy:  0.7049\n",
      "Validation Loss:  0.9558\n",
      "Validation Accuracy:  0.7104\n",
      "Validation Loss:  0.9689\n",
      "Validation Accuracy:  0.7104\n",
      "Validation Loss:  0.9345\n",
      "TRAINING CLIENT 6\n",
      "Validation Accuracy:  0.6831\n",
      "Validation Loss:  0.9863\n",
      "Validation Accuracy:  0.6831\n",
      "Validation Loss:  0.9686\n",
      "Validation Accuracy:  0.6995\n",
      "Validation Loss:  0.9857\n",
      "Validation Accuracy:  0.6885\n",
      "Validation Loss:  0.9538\n",
      "Validation Accuracy:  0.6995\n",
      "Validation Loss:  0.9463\n",
      "Validation Accuracy:  0.6995\n",
      "Validation Loss:  0.9053\n",
      "Validation Accuracy:  0.7049\n",
      "Validation Loss:  0.9277\n",
      "Validation Accuracy:  0.7049\n",
      "Validation Loss:  0.9065\n",
      "TRAINING INDEPENDENT...\n",
      "Validation Accuracy:  0.6831\n",
      "Validation Loss:  0.9876\n",
      "Validation Accuracy:  0.6776\n",
      "Validation Loss:  0.9762\n",
      "Validation Accuracy:  0.6776\n",
      "Validation Loss:  0.9741\n",
      "Validation Accuracy:  0.6831\n",
      "Validation Loss:  0.9575\n",
      "Validation Accuracy:  0.6885\n",
      "Validation Loss:  0.9353\n",
      "Validation Accuracy:  0.6940\n",
      "Validation Loss:  0.9486\n",
      "Validation Accuracy:  0.7104\n",
      "Validation Loss:  0.9093\n",
      "Validation Accuracy:  0.7104\n",
      "Validation Loss:  0.8998\n",
      "TRAINING CLIENT 7\n",
      "Validation Accuracy:  0.6776\n",
      "Validation Loss:  0.9657\n",
      "Validation Accuracy:  0.6831\n",
      "Validation Loss:  0.9768\n",
      "Validation Accuracy:  0.6831\n",
      "Validation Loss:  0.9726\n",
      "Validation Accuracy:  0.6885\n",
      "Validation Loss:  0.9387\n",
      "Validation Accuracy:  0.6885\n",
      "Validation Loss:  0.9451\n",
      "Validation Accuracy:  0.6940\n",
      "Validation Loss:  0.9138\n",
      "Validation Accuracy:  0.6995\n",
      "Validation Loss:  0.9119\n",
      "Validation Accuracy:  0.7049\n",
      "Validation Loss:  0.8998\n",
      "TRAINING INDEPENDENT...\n",
      "Validation Accuracy:  0.6284\n",
      "Validation Loss:  0.9974\n",
      "Validation Accuracy:  0.6448\n",
      "Validation Loss:  0.9901\n",
      "Validation Accuracy:  0.6667\n",
      "Validation Loss:  0.9980\n",
      "Validation Accuracy:  0.6776\n",
      "Validation Loss:  0.9786\n",
      "Validation Accuracy:  0.6776\n",
      "Validation Loss:  0.9602\n",
      "Validation Accuracy:  0.6776\n",
      "Validation Loss:  0.9480\n",
      "Validation Accuracy:  0.6776\n",
      "Validation Loss:  0.9317\n",
      "Validation Accuracy:  0.6885\n",
      "Validation Loss:  0.9353\n",
      "TRAINING CLIENT 8\n",
      "Validation Accuracy:  0.6721\n",
      "Validation Loss:  1.0004\n",
      "Validation Accuracy:  0.6831\n",
      "Validation Loss:  0.9702\n",
      "Validation Accuracy:  0.6776\n",
      "Validation Loss:  0.9746\n",
      "Validation Accuracy:  0.6831\n",
      "Validation Loss:  0.9626\n",
      "Validation Accuracy:  0.6885\n",
      "Validation Loss:  0.9431\n",
      "Validation Accuracy:  0.6940\n",
      "Validation Loss:  0.9311\n",
      "Validation Accuracy:  0.6940\n",
      "Validation Loss:  0.9178\n",
      "Validation Accuracy:  0.6940\n",
      "Validation Loss:  0.8970\n",
      "TRAINING INDEPENDENT...\n",
      "Validation Accuracy:  0.6393\n",
      "Validation Loss:  1.0091\n",
      "Validation Accuracy:  0.6557\n",
      "Validation Loss:  0.9944\n",
      "Validation Accuracy:  0.6831\n",
      "Validation Loss:  0.9736\n",
      "Validation Accuracy:  0.6885\n",
      "Validation Loss:  0.9516\n",
      "Validation Accuracy:  0.6940\n",
      "Validation Loss:  0.9281\n",
      "Validation Accuracy:  0.6995\n",
      "Validation Loss:  0.9354\n",
      "Validation Accuracy:  0.6940\n",
      "Validation Loss:  0.9150\n",
      "Validation Accuracy:  0.7049\n",
      "Validation Loss:  0.9143\n",
      "TRAINING CLIENT 9\n",
      "Validation Accuracy:  0.6940\n",
      "Validation Loss:  0.9959\n",
      "Validation Accuracy:  0.7104\n",
      "Validation Loss:  0.9887\n",
      "Validation Accuracy:  0.7104\n",
      "Validation Loss:  0.9528\n",
      "Validation Accuracy:  0.7104\n",
      "Validation Loss:  0.9759\n",
      "Validation Accuracy:  0.7049\n",
      "Validation Loss:  0.9705\n",
      "Validation Accuracy:  0.7104\n",
      "Validation Loss:  0.9319\n",
      "Validation Accuracy:  0.7049\n",
      "Validation Loss:  0.9114\n",
      "Validation Accuracy:  0.7104\n",
      "Validation Loss:  0.9377\n",
      "TRAINING INDEPENDENT...\n",
      "Validation Accuracy:  0.6885\n",
      "Validation Loss:  0.9920\n",
      "Validation Accuracy:  0.6885\n",
      "Validation Loss:  0.9972\n",
      "Validation Accuracy:  0.6995\n",
      "Validation Loss:  0.9919\n",
      "Validation Accuracy:  0.7049\n",
      "Validation Loss:  0.9615\n",
      "Validation Accuracy:  0.7049\n",
      "Validation Loss:  0.9549\n",
      "Validation Accuracy:  0.7049\n",
      "Validation Loss:  0.9641\n",
      "Validation Accuracy:  0.7049\n",
      "Validation Loss:  0.9364\n",
      "Validation Accuracy:  0.7049\n",
      "Validation Loss:  0.9559\n",
      "Loss = 1.2164862155914307, Acc = 0.4918032786885246\n",
      "ROUND: 3\n",
      "--------------------------------------------------\n",
      "TRAINING CLIENT 0\n",
      "Validation Accuracy:  0.7213\n",
      "Validation Loss:  0.8853\n",
      "Validation Accuracy:  0.7213\n",
      "Validation Loss:  0.8735\n",
      "Validation Accuracy:  0.7213\n",
      "Validation Loss:  0.8835\n",
      "Validation Accuracy:  0.7268\n",
      "Validation Loss:  0.8734\n",
      "Validation Accuracy:  0.7213\n",
      "Validation Loss:  0.8618\n",
      "Validation Accuracy:  0.7213\n",
      "Validation Loss:  0.8458\n",
      "Validation Accuracy:  0.7322\n",
      "Validation Loss:  0.8390\n",
      "Validation Accuracy:  0.7322\n",
      "Validation Loss:  0.8280\n",
      "TRAINING INDEPENDENT...\n",
      "Validation Accuracy:  0.7104\n",
      "Validation Loss:  0.8800\n",
      "Validation Accuracy:  0.7158\n",
      "Validation Loss:  0.8830\n",
      "Validation Accuracy:  0.7158\n",
      "Validation Loss:  0.8882\n",
      "Validation Accuracy:  0.7158\n",
      "Validation Loss:  0.8824\n",
      "Validation Accuracy:  0.7213\n",
      "Validation Loss:  0.8802\n",
      "Validation Accuracy:  0.7268\n",
      "Validation Loss:  0.8724\n",
      "Validation Accuracy:  0.7268\n",
      "Validation Loss:  0.8574\n",
      "Validation Accuracy:  0.7268\n",
      "Validation Loss:  0.8483\n",
      "TRAINING CLIENT 1\n",
      "Validation Accuracy:  0.7104\n",
      "Validation Loss:  0.8880\n",
      "Validation Accuracy:  0.7049\n",
      "Validation Loss:  0.8977\n",
      "Validation Accuracy:  0.7049\n",
      "Validation Loss:  0.8692\n",
      "Validation Accuracy:  0.7049\n",
      "Validation Loss:  0.8745\n",
      "Validation Accuracy:  0.7049\n",
      "Validation Loss:  0.8478\n",
      "Validation Accuracy:  0.7049\n",
      "Validation Loss:  0.8743\n",
      "Validation Accuracy:  0.7049\n",
      "Validation Loss:  0.8605\n",
      "Validation Accuracy:  0.7104\n",
      "Validation Loss:  0.8506\n",
      "TRAINING INDEPENDENT...\n",
      "Validation Accuracy:  0.6940\n",
      "Validation Loss:  0.9181\n",
      "Validation Accuracy:  0.6940\n",
      "Validation Loss:  0.9076\n",
      "Validation Accuracy:  0.6940\n",
      "Validation Loss:  0.9085\n",
      "Validation Accuracy:  0.6940\n",
      "Validation Loss:  0.8963\n",
      "Validation Accuracy:  0.6940\n",
      "Validation Loss:  0.8894\n",
      "Validation Accuracy:  0.6940\n",
      "Validation Loss:  0.8836\n",
      "Validation Accuracy:  0.6995\n",
      "Validation Loss:  0.8608\n",
      "Validation Accuracy:  0.6940\n",
      "Validation Loss:  0.8864\n",
      "TRAINING CLIENT 2\n",
      "Validation Accuracy:  0.7158\n",
      "Validation Loss:  0.9030\n",
      "Validation Accuracy:  0.7104\n",
      "Validation Loss:  0.8928\n",
      "Validation Accuracy:  0.7158\n",
      "Validation Loss:  0.9098\n",
      "Validation Accuracy:  0.7158\n",
      "Validation Loss:  0.8769\n",
      "Validation Accuracy:  0.7213\n",
      "Validation Loss:  0.8542\n",
      "Validation Accuracy:  0.7213\n",
      "Validation Loss:  0.8703\n",
      "Validation Accuracy:  0.7213\n",
      "Validation Loss:  0.8669\n",
      "Validation Accuracy:  0.7213\n",
      "Validation Loss:  0.8287\n",
      "TRAINING INDEPENDENT...\n",
      "Validation Accuracy:  0.6995\n",
      "Validation Loss:  0.9395\n",
      "Validation Accuracy:  0.6940\n",
      "Validation Loss:  0.9425\n",
      "Validation Accuracy:  0.6995\n",
      "Validation Loss:  0.9090\n",
      "Validation Accuracy:  0.6995\n",
      "Validation Loss:  0.9163\n",
      "Validation Accuracy:  0.6995\n",
      "Validation Loss:  0.8902\n",
      "Validation Accuracy:  0.6995\n",
      "Validation Loss:  0.9162\n",
      "Validation Accuracy:  0.6995\n",
      "Validation Loss:  0.8818\n",
      "Validation Accuracy:  0.6995\n",
      "Validation Loss:  0.8784\n",
      "TRAINING CLIENT 3\n",
      "Validation Accuracy:  0.7104\n",
      "Validation Loss:  0.8822\n",
      "Validation Accuracy:  0.7104\n",
      "Validation Loss:  0.9125\n",
      "Validation Accuracy:  0.7104\n",
      "Validation Loss:  0.9108\n",
      "Validation Accuracy:  0.7158\n",
      "Validation Loss:  0.8836\n",
      "Validation Accuracy:  0.7158\n",
      "Validation Loss:  0.8813\n",
      "Validation Accuracy:  0.7158\n",
      "Validation Loss:  0.8659\n",
      "Validation Accuracy:  0.7158\n",
      "Validation Loss:  0.8621\n",
      "Validation Accuracy:  0.7158\n",
      "Validation Loss:  0.8294\n",
      "TRAINING INDEPENDENT...\n",
      "Validation Accuracy:  0.6995\n",
      "Validation Loss:  0.9379\n",
      "Validation Accuracy:  0.7049\n",
      "Validation Loss:  0.9194\n",
      "Validation Accuracy:  0.7158\n",
      "Validation Loss:  0.9082\n",
      "Validation Accuracy:  0.7104\n",
      "Validation Loss:  0.8931\n",
      "Validation Accuracy:  0.7049\n",
      "Validation Loss:  0.9331\n",
      "Validation Accuracy:  0.7104\n",
      "Validation Loss:  0.8854\n",
      "Validation Accuracy:  0.7104\n",
      "Validation Loss:  0.9025\n",
      "Validation Accuracy:  0.7104\n",
      "Validation Loss:  0.8627\n",
      "TRAINING CLIENT 4\n",
      "Validation Accuracy:  0.7104\n",
      "Validation Loss:  0.9275\n",
      "Validation Accuracy:  0.7104\n",
      "Validation Loss:  0.9050\n",
      "Validation Accuracy:  0.7104\n",
      "Validation Loss:  0.8635\n",
      "Validation Accuracy:  0.7158\n",
      "Validation Loss:  0.8678\n",
      "Validation Accuracy:  0.7213\n",
      "Validation Loss:  0.8622\n",
      "Validation Accuracy:  0.7213\n",
      "Validation Loss:  0.8457\n",
      "Validation Accuracy:  0.7158\n",
      "Validation Loss:  0.8618\n",
      "Validation Accuracy:  0.7158\n",
      "Validation Loss:  0.8496\n",
      "TRAINING INDEPENDENT...\n",
      "Validation Accuracy:  0.7049\n",
      "Validation Loss:  0.9007\n",
      "Validation Accuracy:  0.7104\n",
      "Validation Loss:  0.8812\n",
      "Validation Accuracy:  0.7104\n",
      "Validation Loss:  0.8784\n",
      "Validation Accuracy:  0.7104\n",
      "Validation Loss:  0.9213\n",
      "Validation Accuracy:  0.7104\n",
      "Validation Loss:  0.8640\n",
      "Validation Accuracy:  0.7104\n",
      "Validation Loss:  0.8767\n",
      "Validation Accuracy:  0.7104\n",
      "Validation Loss:  0.8714\n",
      "Validation Accuracy:  0.7158\n",
      "Validation Loss:  0.8705\n",
      "TRAINING CLIENT 5\n",
      "Validation Accuracy:  0.6940\n",
      "Validation Loss:  0.9000\n",
      "Validation Accuracy:  0.7104\n",
      "Validation Loss:  0.8785\n",
      "Validation Accuracy:  0.7104\n",
      "Validation Loss:  0.8724\n",
      "Validation Accuracy:  0.7213\n",
      "Validation Loss:  0.8925\n",
      "Validation Accuracy:  0.7158\n",
      "Validation Loss:  0.8841\n",
      "Validation Accuracy:  0.7268\n",
      "Validation Loss:  0.8716\n",
      "Validation Accuracy:  0.7268\n",
      "Validation Loss:  0.8456\n",
      "Validation Accuracy:  0.7268\n",
      "Validation Loss:  0.8232\n",
      "TRAINING INDEPENDENT...\n",
      "Validation Accuracy:  0.7104\n",
      "Validation Loss:  0.9429\n",
      "Validation Accuracy:  0.7158\n",
      "Validation Loss:  0.9196\n",
      "Validation Accuracy:  0.7158\n",
      "Validation Loss:  0.9383\n",
      "Validation Accuracy:  0.7158\n",
      "Validation Loss:  0.9073\n",
      "Validation Accuracy:  0.7158\n",
      "Validation Loss:  0.8846\n",
      "Validation Accuracy:  0.7104\n",
      "Validation Loss:  0.8888\n",
      "Validation Accuracy:  0.7158\n",
      "Validation Loss:  0.8782\n",
      "Validation Accuracy:  0.7158\n",
      "Validation Loss:  0.8737\n",
      "TRAINING CLIENT 6\n",
      "Validation Accuracy:  0.7158\n",
      "Validation Loss:  0.9099\n",
      "Validation Accuracy:  0.7104\n",
      "Validation Loss:  0.9113\n",
      "Validation Accuracy:  0.7158\n",
      "Validation Loss:  0.8726\n",
      "Validation Accuracy:  0.7158\n",
      "Validation Loss:  0.9094\n",
      "Validation Accuracy:  0.7158\n",
      "Validation Loss:  0.8637\n",
      "Validation Accuracy:  0.7213\n",
      "Validation Loss:  0.8606\n",
      "Validation Accuracy:  0.7213\n",
      "Validation Loss:  0.8494\n",
      "Validation Accuracy:  0.7213\n",
      "Validation Loss:  0.8344\n",
      "TRAINING INDEPENDENT...\n",
      "Validation Accuracy:  0.7104\n",
      "Validation Loss:  0.9002\n",
      "Validation Accuracy:  0.7104\n",
      "Validation Loss:  0.8853\n",
      "Validation Accuracy:  0.7104\n",
      "Validation Loss:  0.8955\n",
      "Validation Accuracy:  0.7104\n",
      "Validation Loss:  0.8528\n",
      "Validation Accuracy:  0.7104\n",
      "Validation Loss:  0.8665\n",
      "Validation Accuracy:  0.7104\n",
      "Validation Loss:  0.8613\n",
      "Validation Accuracy:  0.7104\n",
      "Validation Loss:  0.8595\n",
      "Validation Accuracy:  0.7158\n",
      "Validation Loss:  0.8274\n",
      "TRAINING CLIENT 7\n",
      "Validation Accuracy:  0.7049\n",
      "Validation Loss:  0.9243\n",
      "Validation Accuracy:  0.7104\n",
      "Validation Loss:  0.8730\n",
      "Validation Accuracy:  0.7104\n",
      "Validation Loss:  0.8715\n",
      "Validation Accuracy:  0.7104\n",
      "Validation Loss:  0.8699\n",
      "Validation Accuracy:  0.7104\n",
      "Validation Loss:  0.8705\n",
      "Validation Accuracy:  0.7158\n",
      "Validation Loss:  0.8643\n",
      "Validation Accuracy:  0.7213\n",
      "Validation Loss:  0.8896\n",
      "Validation Accuracy:  0.7268\n",
      "Validation Loss:  0.8544\n",
      "TRAINING INDEPENDENT...\n",
      "Validation Accuracy:  0.6995\n",
      "Validation Loss:  0.8970\n",
      "Validation Accuracy:  0.6995\n",
      "Validation Loss:  0.8946\n",
      "Validation Accuracy:  0.7104\n",
      "Validation Loss:  0.8802\n",
      "Validation Accuracy:  0.7049\n",
      "Validation Loss:  0.8837\n",
      "Validation Accuracy:  0.7049\n",
      "Validation Loss:  0.8723\n",
      "Validation Accuracy:  0.7049\n",
      "Validation Loss:  0.8693\n",
      "Validation Accuracy:  0.7104\n",
      "Validation Loss:  0.8819\n",
      "Validation Accuracy:  0.7158\n",
      "Validation Loss:  0.8623\n",
      "TRAINING CLIENT 8\n",
      "Validation Accuracy:  0.6995\n",
      "Validation Loss:  0.8934\n",
      "Validation Accuracy:  0.7104\n",
      "Validation Loss:  0.8783\n",
      "Validation Accuracy:  0.7104\n",
      "Validation Loss:  0.8577\n",
      "Validation Accuracy:  0.7104\n",
      "Validation Loss:  0.8616\n",
      "Validation Accuracy:  0.7268\n",
      "Validation Loss:  0.8519\n",
      "Validation Accuracy:  0.7213\n",
      "Validation Loss:  0.8410\n",
      "Validation Accuracy:  0.7268\n",
      "Validation Loss:  0.8333\n",
      "Validation Accuracy:  0.7213\n",
      "Validation Loss:  0.8422\n",
      "TRAINING INDEPENDENT...\n",
      "Validation Accuracy:  0.6995\n",
      "Validation Loss:  0.8956\n",
      "Validation Accuracy:  0.6995\n",
      "Validation Loss:  0.9065\n",
      "Validation Accuracy:  0.6995\n",
      "Validation Loss:  0.8864\n",
      "Validation Accuracy:  0.7104\n",
      "Validation Loss:  0.8929\n",
      "Validation Accuracy:  0.7104\n",
      "Validation Loss:  0.8849\n",
      "Validation Accuracy:  0.7158\n",
      "Validation Loss:  0.8381\n",
      "Validation Accuracy:  0.7213\n",
      "Validation Loss:  0.8275\n",
      "Validation Accuracy:  0.7213\n",
      "Validation Loss:  0.8745\n",
      "TRAINING CLIENT 9\n",
      "Validation Accuracy:  0.7104\n",
      "Validation Loss:  0.8965\n",
      "Validation Accuracy:  0.7158\n",
      "Validation Loss:  0.9211\n",
      "Validation Accuracy:  0.7158\n",
      "Validation Loss:  0.9088\n",
      "Validation Accuracy:  0.7213\n",
      "Validation Loss:  0.8573\n",
      "Validation Accuracy:  0.7213\n",
      "Validation Loss:  0.8956\n",
      "Validation Accuracy:  0.7213\n",
      "Validation Loss:  0.8902\n",
      "Validation Accuracy:  0.7213\n",
      "Validation Loss:  0.8694\n",
      "Validation Accuracy:  0.7213\n",
      "Validation Loss:  0.8498\n",
      "TRAINING INDEPENDENT...\n",
      "Validation Accuracy:  0.7049\n",
      "Validation Loss:  0.9297\n",
      "Validation Accuracy:  0.7049\n",
      "Validation Loss:  0.9406\n",
      "Validation Accuracy:  0.7049\n",
      "Validation Loss:  0.9609\n",
      "Validation Accuracy:  0.7104\n",
      "Validation Loss:  0.9451\n",
      "Validation Accuracy:  0.7104\n",
      "Validation Loss:  0.9264\n",
      "Validation Accuracy:  0.7049\n",
      "Validation Loss:  0.9030\n",
      "Validation Accuracy:  0.7049\n",
      "Validation Loss:  0.9141\n",
      "Validation Accuracy:  0.7104\n",
      "Validation Loss:  0.8911\n",
      "Loss = 1.2101592421531677, Acc = 0.4918032786885246\n",
      "ROUND: 4\n",
      "--------------------------------------------------\n",
      "TRAINING CLIENT 0\n",
      "Validation Accuracy:  0.7268\n",
      "Validation Loss:  0.8531\n",
      "Validation Accuracy:  0.7268\n",
      "Validation Loss:  0.8239\n",
      "Validation Accuracy:  0.7268\n",
      "Validation Loss:  0.8157\n",
      "Validation Accuracy:  0.7268\n",
      "Validation Loss:  0.8359\n",
      "Validation Accuracy:  0.7268\n",
      "Validation Loss:  0.8099\n",
      "Validation Accuracy:  0.7322\n",
      "Validation Loss:  0.8236\n",
      "Validation Accuracy:  0.7322\n",
      "Validation Loss:  0.7943\n",
      "Validation Accuracy:  0.7322\n",
      "Validation Loss:  0.7888\n",
      "TRAINING INDEPENDENT...\n",
      "Validation Accuracy:  0.7268\n",
      "Validation Loss:  0.8516\n",
      "Validation Accuracy:  0.7322\n",
      "Validation Loss:  0.8517\n",
      "Validation Accuracy:  0.7322\n",
      "Validation Loss:  0.8525\n",
      "Validation Accuracy:  0.7322\n",
      "Validation Loss:  0.8342\n",
      "Validation Accuracy:  0.7322\n",
      "Validation Loss:  0.8658\n",
      "Validation Accuracy:  0.7322\n",
      "Validation Loss:  0.8208\n",
      "Validation Accuracy:  0.7322\n",
      "Validation Loss:  0.8231\n",
      "Validation Accuracy:  0.7322\n",
      "Validation Loss:  0.8529\n",
      "TRAINING CLIENT 1\n",
      "Validation Accuracy:  0.7322\n",
      "Validation Loss:  0.8236\n",
      "Validation Accuracy:  0.7322\n",
      "Validation Loss:  0.8302\n",
      "Validation Accuracy:  0.7322\n",
      "Validation Loss:  0.8339\n",
      "Validation Accuracy:  0.7322\n",
      "Validation Loss:  0.8303\n",
      "Validation Accuracy:  0.7322\n",
      "Validation Loss:  0.8008\n",
      "Validation Accuracy:  0.7322\n",
      "Validation Loss:  0.8058\n",
      "Validation Accuracy:  0.7268\n",
      "Validation Loss:  0.7984\n",
      "Validation Accuracy:  0.7268\n",
      "Validation Loss:  0.8123\n",
      "TRAINING INDEPENDENT...\n",
      "Validation Accuracy:  0.6995\n",
      "Validation Loss:  0.8708\n",
      "Validation Accuracy:  0.7104\n",
      "Validation Loss:  0.8690\n",
      "Validation Accuracy:  0.7104\n",
      "Validation Loss:  0.8646\n",
      "Validation Accuracy:  0.7104\n",
      "Validation Loss:  0.8425\n",
      "Validation Accuracy:  0.7104\n",
      "Validation Loss:  0.8429\n",
      "Validation Accuracy:  0.7158\n",
      "Validation Loss:  0.8599\n",
      "Validation Accuracy:  0.7104\n",
      "Validation Loss:  0.8323\n",
      "Validation Accuracy:  0.7158\n",
      "Validation Loss:  0.8506\n",
      "TRAINING CLIENT 2\n",
      "Validation Accuracy:  0.7322\n",
      "Validation Loss:  0.8192\n",
      "Validation Accuracy:  0.7322\n",
      "Validation Loss:  0.8343\n",
      "Validation Accuracy:  0.7268\n",
      "Validation Loss:  0.8222\n",
      "Validation Accuracy:  0.7268\n",
      "Validation Loss:  0.8484\n",
      "Validation Accuracy:  0.7268\n",
      "Validation Loss:  0.8425\n",
      "Validation Accuracy:  0.7268\n",
      "Validation Loss:  0.8093\n",
      "Validation Accuracy:  0.7268\n",
      "Validation Loss:  0.7934\n",
      "Validation Accuracy:  0.7268\n",
      "Validation Loss:  0.8068\n",
      "TRAINING INDEPENDENT...\n",
      "Validation Accuracy:  0.6995\n",
      "Validation Loss:  0.9088\n",
      "Validation Accuracy:  0.6995\n",
      "Validation Loss:  0.8664\n",
      "Validation Accuracy:  0.7049\n",
      "Validation Loss:  0.8523\n",
      "Validation Accuracy:  0.7049\n",
      "Validation Loss:  0.8597\n",
      "Validation Accuracy:  0.6995\n",
      "Validation Loss:  0.8556\n",
      "Validation Accuracy:  0.6995\n",
      "Validation Loss:  0.8541\n",
      "Validation Accuracy:  0.7049\n",
      "Validation Loss:  0.8326\n",
      "Validation Accuracy:  0.7049\n",
      "Validation Loss:  0.8366\n",
      "TRAINING CLIENT 3\n",
      "Validation Accuracy:  0.7268\n",
      "Validation Loss:  0.8287\n",
      "Validation Accuracy:  0.7268\n",
      "Validation Loss:  0.8446\n",
      "Validation Accuracy:  0.7268\n",
      "Validation Loss:  0.8132\n",
      "Validation Accuracy:  0.7322\n",
      "Validation Loss:  0.8360\n",
      "Validation Accuracy:  0.7268\n",
      "Validation Loss:  0.8217\n",
      "Validation Accuracy:  0.7322\n",
      "Validation Loss:  0.8098\n",
      "Validation Accuracy:  0.7322\n",
      "Validation Loss:  0.8232\n",
      "Validation Accuracy:  0.7322\n",
      "Validation Loss:  0.8178\n",
      "TRAINING INDEPENDENT...\n",
      "Validation Accuracy:  0.7104\n",
      "Validation Loss:  0.8821\n",
      "Validation Accuracy:  0.7104\n",
      "Validation Loss:  0.8726\n",
      "Validation Accuracy:  0.7104\n",
      "Validation Loss:  0.8843\n",
      "Validation Accuracy:  0.7158\n",
      "Validation Loss:  0.8815\n",
      "Validation Accuracy:  0.7158\n",
      "Validation Loss:  0.8522\n",
      "Validation Accuracy:  0.7104\n",
      "Validation Loss:  0.8482\n",
      "Validation Accuracy:  0.7104\n",
      "Validation Loss:  0.8677\n",
      "Validation Accuracy:  0.7104\n",
      "Validation Loss:  0.8452\n",
      "TRAINING CLIENT 4\n",
      "Validation Accuracy:  0.7268\n",
      "Validation Loss:  0.8519\n",
      "Validation Accuracy:  0.7268\n",
      "Validation Loss:  0.8592\n",
      "Validation Accuracy:  0.7268\n",
      "Validation Loss:  0.8180\n",
      "Validation Accuracy:  0.7268\n",
      "Validation Loss:  0.7944\n",
      "Validation Accuracy:  0.7268\n",
      "Validation Loss:  0.8231\n",
      "Validation Accuracy:  0.7268\n",
      "Validation Loss:  0.8096\n",
      "Validation Accuracy:  0.7268\n",
      "Validation Loss:  0.8133\n",
      "Validation Accuracy:  0.7268\n",
      "Validation Loss:  0.8166\n",
      "TRAINING INDEPENDENT...\n",
      "Validation Accuracy:  0.7158\n",
      "Validation Loss:  0.8728\n",
      "Validation Accuracy:  0.7213\n",
      "Validation Loss:  0.8484\n",
      "Validation Accuracy:  0.7213\n",
      "Validation Loss:  0.8393\n",
      "Validation Accuracy:  0.7158\n",
      "Validation Loss:  0.8412\n",
      "Validation Accuracy:  0.7213\n",
      "Validation Loss:  0.8332\n",
      "Validation Accuracy:  0.7213\n",
      "Validation Loss:  0.8276\n",
      "Validation Accuracy:  0.7213\n",
      "Validation Loss:  0.8234\n",
      "Validation Accuracy:  0.7213\n",
      "Validation Loss:  0.8221\n",
      "TRAINING CLIENT 5\n",
      "Validation Accuracy:  0.7268\n",
      "Validation Loss:  0.8464\n",
      "Validation Accuracy:  0.7322\n",
      "Validation Loss:  0.8419\n",
      "Validation Accuracy:  0.7322\n",
      "Validation Loss:  0.8358\n",
      "Validation Accuracy:  0.7322\n",
      "Validation Loss:  0.8331\n",
      "Validation Accuracy:  0.7322\n",
      "Validation Loss:  0.8272\n",
      "Validation Accuracy:  0.7322\n",
      "Validation Loss:  0.8176\n",
      "Validation Accuracy:  0.7322\n",
      "Validation Loss:  0.7955\n",
      "Validation Accuracy:  0.7322\n",
      "Validation Loss:  0.8029\n",
      "TRAINING INDEPENDENT...\n",
      "Validation Accuracy:  0.7158\n",
      "Validation Loss:  0.8791\n",
      "Validation Accuracy:  0.7104\n",
      "Validation Loss:  0.8840\n",
      "Validation Accuracy:  0.7158\n",
      "Validation Loss:  0.8822\n",
      "Validation Accuracy:  0.7158\n",
      "Validation Loss:  0.8626\n",
      "Validation Accuracy:  0.7158\n",
      "Validation Loss:  0.8626\n",
      "Validation Accuracy:  0.7158\n",
      "Validation Loss:  0.8554\n",
      "Validation Accuracy:  0.7104\n",
      "Validation Loss:  0.8368\n",
      "Validation Accuracy:  0.7104\n",
      "Validation Loss:  0.8556\n",
      "TRAINING CLIENT 6\n",
      "Validation Accuracy:  0.7268\n",
      "Validation Loss:  0.8525\n",
      "Validation Accuracy:  0.7268\n",
      "Validation Loss:  0.8287\n",
      "Validation Accuracy:  0.7268\n",
      "Validation Loss:  0.8356\n",
      "Validation Accuracy:  0.7322\n",
      "Validation Loss:  0.7898\n",
      "Validation Accuracy:  0.7322\n",
      "Validation Loss:  0.8041\n",
      "Validation Accuracy:  0.7322\n",
      "Validation Loss:  0.7868\n",
      "Validation Accuracy:  0.7322\n",
      "Validation Loss:  0.8032\n",
      "Validation Accuracy:  0.7322\n",
      "Validation Loss:  0.8012\n",
      "TRAINING INDEPENDENT...\n",
      "Validation Accuracy:  0.7268\n",
      "Validation Loss:  0.8678\n",
      "Validation Accuracy:  0.7268\n",
      "Validation Loss:  0.8717\n",
      "Validation Accuracy:  0.7268\n",
      "Validation Loss:  0.8314\n",
      "Validation Accuracy:  0.7268\n",
      "Validation Loss:  0.8249\n",
      "Validation Accuracy:  0.7268\n",
      "Validation Loss:  0.8081\n",
      "Validation Accuracy:  0.7322\n",
      "Validation Loss:  0.8227\n",
      "Validation Accuracy:  0.7268\n",
      "Validation Loss:  0.8204\n",
      "Validation Accuracy:  0.7322\n",
      "Validation Loss:  0.8115\n",
      "TRAINING CLIENT 7\n",
      "Validation Accuracy:  0.7268\n",
      "Validation Loss:  0.8465\n",
      "Validation Accuracy:  0.7268\n",
      "Validation Loss:  0.8278\n",
      "Validation Accuracy:  0.7322\n",
      "Validation Loss:  0.8222\n",
      "Validation Accuracy:  0.7322\n",
      "Validation Loss:  0.8155\n",
      "Validation Accuracy:  0.7322\n",
      "Validation Loss:  0.8195\n",
      "Validation Accuracy:  0.7322\n",
      "Validation Loss:  0.7903\n",
      "Validation Accuracy:  0.7322\n",
      "Validation Loss:  0.7851\n",
      "Validation Accuracy:  0.7322\n",
      "Validation Loss:  0.8059\n",
      "TRAINING INDEPENDENT...\n",
      "Validation Accuracy:  0.7158\n",
      "Validation Loss:  0.8432\n",
      "Validation Accuracy:  0.7213\n",
      "Validation Loss:  0.8508\n",
      "Validation Accuracy:  0.7213\n",
      "Validation Loss:  0.8219\n",
      "Validation Accuracy:  0.7268\n",
      "Validation Loss:  0.8253\n",
      "Validation Accuracy:  0.7322\n",
      "Validation Loss:  0.8378\n",
      "Validation Accuracy:  0.7268\n",
      "Validation Loss:  0.8226\n",
      "Validation Accuracy:  0.7377\n",
      "Validation Loss:  0.7859\n",
      "Validation Accuracy:  0.7432\n",
      "Validation Loss:  0.7823\n",
      "TRAINING CLIENT 8\n",
      "Validation Accuracy:  0.7213\n",
      "Validation Loss:  0.8198\n",
      "Validation Accuracy:  0.7268\n",
      "Validation Loss:  0.8709\n",
      "Validation Accuracy:  0.7322\n",
      "Validation Loss:  0.8042\n",
      "Validation Accuracy:  0.7322\n",
      "Validation Loss:  0.8245\n",
      "Validation Accuracy:  0.7322\n",
      "Validation Loss:  0.7941\n",
      "Validation Accuracy:  0.7322\n",
      "Validation Loss:  0.8063\n",
      "Validation Accuracy:  0.7322\n",
      "Validation Loss:  0.7855\n",
      "Validation Accuracy:  0.7322\n",
      "Validation Loss:  0.7887\n",
      "TRAINING INDEPENDENT...\n",
      "Validation Accuracy:  0.7213\n",
      "Validation Loss:  0.8474\n",
      "Validation Accuracy:  0.7268\n",
      "Validation Loss:  0.8247\n",
      "Validation Accuracy:  0.7377\n",
      "Validation Loss:  0.8366\n",
      "Validation Accuracy:  0.7377\n",
      "Validation Loss:  0.8460\n",
      "Validation Accuracy:  0.7377\n",
      "Validation Loss:  0.8214\n",
      "Validation Accuracy:  0.7377\n",
      "Validation Loss:  0.7878\n",
      "Validation Accuracy:  0.7377\n",
      "Validation Loss:  0.8064\n",
      "Validation Accuracy:  0.7432\n",
      "Validation Loss:  0.8011\n",
      "TRAINING CLIENT 9\n",
      "Validation Accuracy:  0.7268\n",
      "Validation Loss:  0.8451\n",
      "Validation Accuracy:  0.7268\n",
      "Validation Loss:  0.8522\n",
      "Validation Accuracy:  0.7268\n",
      "Validation Loss:  0.8464\n",
      "Validation Accuracy:  0.7268\n",
      "Validation Loss:  0.8179\n",
      "Validation Accuracy:  0.7268\n",
      "Validation Loss:  0.8288\n",
      "Validation Accuracy:  0.7268\n",
      "Validation Loss:  0.7937\n",
      "Validation Accuracy:  0.7268\n",
      "Validation Loss:  0.8170\n",
      "Validation Accuracy:  0.7268\n",
      "Validation Loss:  0.8314\n",
      "TRAINING INDEPENDENT...\n",
      "Validation Accuracy:  0.7104\n",
      "Validation Loss:  0.8760\n",
      "Validation Accuracy:  0.7049\n",
      "Validation Loss:  0.8785\n",
      "Validation Accuracy:  0.7049\n",
      "Validation Loss:  0.8908\n",
      "Validation Accuracy:  0.7049\n",
      "Validation Loss:  0.9026\n",
      "Validation Accuracy:  0.7049\n",
      "Validation Loss:  0.8803\n",
      "Validation Accuracy:  0.7104\n",
      "Validation Loss:  0.8764\n",
      "Validation Accuracy:  0.7049\n",
      "Validation Loss:  0.8890\n",
      "Validation Accuracy:  0.7104\n",
      "Validation Loss:  0.8750\n",
      "Loss = 1.198570157090823, Acc = 0.4918032786885246\n",
      "ROUND: 5\n",
      "--------------------------------------------------\n",
      "TRAINING CLIENT 0\n",
      "Validation Accuracy:  0.7322\n",
      "Validation Loss:  0.7979\n",
      "Validation Accuracy:  0.7322\n",
      "Validation Loss:  0.7871\n",
      "Validation Accuracy:  0.7322\n",
      "Validation Loss:  0.8123\n",
      "Validation Accuracy:  0.7322\n",
      "Validation Loss:  0.8017\n",
      "Validation Accuracy:  0.7322\n",
      "Validation Loss:  0.7899\n",
      "Validation Accuracy:  0.7322\n",
      "Validation Loss:  0.7677\n",
      "Validation Accuracy:  0.7322\n",
      "Validation Loss:  0.7757\n",
      "Validation Accuracy:  0.7322\n",
      "Validation Loss:  0.7693\n",
      "TRAINING INDEPENDENT...\n",
      "Validation Accuracy:  0.7322\n",
      "Validation Loss:  0.8089\n",
      "Validation Accuracy:  0.7322\n",
      "Validation Loss:  0.8232\n",
      "Validation Accuracy:  0.7322\n",
      "Validation Loss:  0.8481\n",
      "Validation Accuracy:  0.7322\n",
      "Validation Loss:  0.7909\n",
      "Validation Accuracy:  0.7322\n",
      "Validation Loss:  0.8577\n",
      "Validation Accuracy:  0.7322\n",
      "Validation Loss:  0.8050\n",
      "Validation Accuracy:  0.7322\n",
      "Validation Loss:  0.8376\n",
      "Validation Accuracy:  0.7322\n",
      "Validation Loss:  0.7951\n",
      "TRAINING CLIENT 1\n",
      "Validation Accuracy:  0.7322\n",
      "Validation Loss:  0.7932\n",
      "Validation Accuracy:  0.7322\n",
      "Validation Loss:  0.7818\n",
      "Validation Accuracy:  0.7322\n",
      "Validation Loss:  0.7882\n",
      "Validation Accuracy:  0.7322\n",
      "Validation Loss:  0.7887\n",
      "Validation Accuracy:  0.7322\n",
      "Validation Loss:  0.7722\n",
      "Validation Accuracy:  0.7322\n",
      "Validation Loss:  0.7729\n",
      "Validation Accuracy:  0.7322\n",
      "Validation Loss:  0.7432\n",
      "Validation Accuracy:  0.7322\n",
      "Validation Loss:  0.7812\n",
      "TRAINING INDEPENDENT...\n",
      "Validation Accuracy:  0.7213\n",
      "Validation Loss:  0.8367\n",
      "Validation Accuracy:  0.7268\n",
      "Validation Loss:  0.8096\n",
      "Validation Accuracy:  0.7268\n",
      "Validation Loss:  0.8142\n",
      "Validation Accuracy:  0.7268\n",
      "Validation Loss:  0.8533\n",
      "Validation Accuracy:  0.7322\n",
      "Validation Loss:  0.8113\n",
      "Validation Accuracy:  0.7322\n",
      "Validation Loss:  0.8231\n",
      "Validation Accuracy:  0.7322\n",
      "Validation Loss:  0.8198\n",
      "Validation Accuracy:  0.7268\n",
      "Validation Loss:  0.8080\n",
      "TRAINING CLIENT 2\n",
      "Validation Accuracy:  0.7322\n",
      "Validation Loss:  0.7832\n",
      "Validation Accuracy:  0.7322\n",
      "Validation Loss:  0.7658\n",
      "Validation Accuracy:  0.7322\n",
      "Validation Loss:  0.7823\n",
      "Validation Accuracy:  0.7322\n",
      "Validation Loss:  0.7816\n",
      "Validation Accuracy:  0.7322\n",
      "Validation Loss:  0.7959\n",
      "Validation Accuracy:  0.7322\n",
      "Validation Loss:  0.7588\n",
      "Validation Accuracy:  0.7322\n",
      "Validation Loss:  0.7558\n",
      "Validation Accuracy:  0.7322\n",
      "Validation Loss:  0.7627\n",
      "TRAINING INDEPENDENT...\n",
      "Validation Accuracy:  0.7049\n",
      "Validation Loss:  0.8847\n",
      "Validation Accuracy:  0.7049\n",
      "Validation Loss:  0.8490\n",
      "Validation Accuracy:  0.6995\n",
      "Validation Loss:  0.8325\n",
      "Validation Accuracy:  0.7049\n",
      "Validation Loss:  0.8148\n",
      "Validation Accuracy:  0.7049\n",
      "Validation Loss:  0.8138\n",
      "Validation Accuracy:  0.7104\n",
      "Validation Loss:  0.8221\n",
      "Validation Accuracy:  0.7049\n",
      "Validation Loss:  0.8358\n",
      "Validation Accuracy:  0.7049\n",
      "Validation Loss:  0.8436\n",
      "TRAINING CLIENT 3\n",
      "Validation Accuracy:  0.7322\n",
      "Validation Loss:  0.7992\n",
      "Validation Accuracy:  0.7322\n",
      "Validation Loss:  0.8114\n",
      "Validation Accuracy:  0.7322\n",
      "Validation Loss:  0.7796\n",
      "Validation Accuracy:  0.7322\n",
      "Validation Loss:  0.7627\n",
      "Validation Accuracy:  0.7322\n",
      "Validation Loss:  0.7665\n",
      "Validation Accuracy:  0.7322\n",
      "Validation Loss:  0.7877\n",
      "Validation Accuracy:  0.7322\n",
      "Validation Loss:  0.7512\n",
      "Validation Accuracy:  0.7322\n",
      "Validation Loss:  0.7666\n",
      "TRAINING INDEPENDENT...\n",
      "Validation Accuracy:  0.7158\n",
      "Validation Loss:  0.8510\n",
      "Validation Accuracy:  0.7104\n",
      "Validation Loss:  0.8337\n",
      "Validation Accuracy:  0.7104\n",
      "Validation Loss:  0.8325\n",
      "Validation Accuracy:  0.7104\n",
      "Validation Loss:  0.8457\n",
      "Validation Accuracy:  0.7104\n",
      "Validation Loss:  0.8570\n",
      "Validation Accuracy:  0.7104\n",
      "Validation Loss:  0.8060\n",
      "Validation Accuracy:  0.7158\n",
      "Validation Loss:  0.8490\n",
      "Validation Accuracy:  0.7158\n",
      "Validation Loss:  0.8148\n",
      "TRAINING CLIENT 4\n",
      "Validation Accuracy:  0.7322\n",
      "Validation Loss:  0.7958\n",
      "Validation Accuracy:  0.7322\n",
      "Validation Loss:  0.7964\n",
      "Validation Accuracy:  0.7322\n",
      "Validation Loss:  0.7908\n",
      "Validation Accuracy:  0.7322\n",
      "Validation Loss:  0.7887\n",
      "Validation Accuracy:  0.7322\n",
      "Validation Loss:  0.7713\n",
      "Validation Accuracy:  0.7322\n",
      "Validation Loss:  0.7743\n",
      "Validation Accuracy:  0.7322\n",
      "Validation Loss:  0.7932\n",
      "Validation Accuracy:  0.7322\n",
      "Validation Loss:  0.7509\n",
      "TRAINING INDEPENDENT...\n",
      "Validation Accuracy:  0.7158\n",
      "Validation Loss:  0.8180\n",
      "Validation Accuracy:  0.7213\n",
      "Validation Loss:  0.8142\n",
      "Validation Accuracy:  0.7158\n",
      "Validation Loss:  0.8213\n",
      "Validation Accuracy:  0.7213\n",
      "Validation Loss:  0.7950\n",
      "Validation Accuracy:  0.7213\n",
      "Validation Loss:  0.8286\n",
      "Validation Accuracy:  0.7158\n",
      "Validation Loss:  0.7937\n",
      "Validation Accuracy:  0.7213\n",
      "Validation Loss:  0.8357\n",
      "Validation Accuracy:  0.7213\n",
      "Validation Loss:  0.8225\n",
      "TRAINING CLIENT 5\n",
      "Validation Accuracy:  0.7322\n",
      "Validation Loss:  0.8369\n",
      "Validation Accuracy:  0.7322\n",
      "Validation Loss:  0.8064\n",
      "Validation Accuracy:  0.7322\n",
      "Validation Loss:  0.7723\n",
      "Validation Accuracy:  0.7322\n",
      "Validation Loss:  0.7796\n",
      "Validation Accuracy:  0.7322\n",
      "Validation Loss:  0.7855\n",
      "Validation Accuracy:  0.7322\n",
      "Validation Loss:  0.7585\n",
      "Validation Accuracy:  0.7322\n",
      "Validation Loss:  0.7653\n",
      "Validation Accuracy:  0.7322\n",
      "Validation Loss:  0.7695\n",
      "TRAINING INDEPENDENT...\n",
      "Validation Accuracy:  0.7158\n",
      "Validation Loss:  0.8223\n",
      "Validation Accuracy:  0.7213\n",
      "Validation Loss:  0.8485\n",
      "Validation Accuracy:  0.7322\n",
      "Validation Loss:  0.8066\n",
      "Validation Accuracy:  0.7213\n",
      "Validation Loss:  0.8188\n",
      "Validation Accuracy:  0.7213\n",
      "Validation Loss:  0.8403\n",
      "Validation Accuracy:  0.7213\n",
      "Validation Loss:  0.8412\n",
      "Validation Accuracy:  0.7268\n",
      "Validation Loss:  0.8650\n",
      "Validation Accuracy:  0.7322\n",
      "Validation Loss:  0.8385\n",
      "TRAINING CLIENT 6\n",
      "Validation Accuracy:  0.7268\n",
      "Validation Loss:  0.8091\n",
      "Validation Accuracy:  0.7268\n",
      "Validation Loss:  0.8052\n",
      "Validation Accuracy:  0.7322\n",
      "Validation Loss:  0.7875\n",
      "Validation Accuracy:  0.7322\n",
      "Validation Loss:  0.7865\n",
      "Validation Accuracy:  0.7322\n",
      "Validation Loss:  0.7734\n",
      "Validation Accuracy:  0.7322\n",
      "Validation Loss:  0.7807\n",
      "Validation Accuracy:  0.7322\n",
      "Validation Loss:  0.7574\n",
      "Validation Accuracy:  0.7322\n",
      "Validation Loss:  0.7549\n",
      "TRAINING INDEPENDENT...\n",
      "Validation Accuracy:  0.7322\n",
      "Validation Loss:  0.8146\n",
      "Validation Accuracy:  0.7322\n",
      "Validation Loss:  0.8037\n",
      "Validation Accuracy:  0.7322\n",
      "Validation Loss:  0.7874\n",
      "Validation Accuracy:  0.7322\n",
      "Validation Loss:  0.8014\n",
      "Validation Accuracy:  0.7322\n",
      "Validation Loss:  0.8011\n",
      "Validation Accuracy:  0.7268\n",
      "Validation Loss:  0.7635\n",
      "Validation Accuracy:  0.7268\n",
      "Validation Loss:  0.7902\n",
      "Validation Accuracy:  0.7322\n",
      "Validation Loss:  0.7823\n",
      "TRAINING CLIENT 7\n",
      "Validation Accuracy:  0.7322\n",
      "Validation Loss:  0.7739\n",
      "Validation Accuracy:  0.7322\n",
      "Validation Loss:  0.8164\n",
      "Validation Accuracy:  0.7322\n",
      "Validation Loss:  0.7738\n",
      "Validation Accuracy:  0.7322\n",
      "Validation Loss:  0.7777\n",
      "Validation Accuracy:  0.7322\n",
      "Validation Loss:  0.7592\n",
      "Validation Accuracy:  0.7322\n",
      "Validation Loss:  0.7602\n",
      "Validation Accuracy:  0.7322\n",
      "Validation Loss:  0.7821\n",
      "Validation Accuracy:  0.7322\n",
      "Validation Loss:  0.7540\n",
      "TRAINING INDEPENDENT...\n",
      "Validation Accuracy:  0.7486\n",
      "Validation Loss:  0.8086\n",
      "Validation Accuracy:  0.7432\n",
      "Validation Loss:  0.8140\n",
      "Validation Accuracy:  0.7486\n",
      "Validation Loss:  0.8144\n",
      "Validation Accuracy:  0.7432\n",
      "Validation Loss:  0.7730\n",
      "Validation Accuracy:  0.7377\n",
      "Validation Loss:  0.7863\n",
      "Validation Accuracy:  0.7486\n",
      "Validation Loss:  0.7890\n",
      "Validation Accuracy:  0.7486\n",
      "Validation Loss:  0.7662\n",
      "Validation Accuracy:  0.7486\n",
      "Validation Loss:  0.7513\n",
      "TRAINING CLIENT 8\n",
      "Validation Accuracy:  0.7322\n",
      "Validation Loss:  0.7840\n",
      "Validation Accuracy:  0.7322\n",
      "Validation Loss:  0.7815\n",
      "Validation Accuracy:  0.7322\n",
      "Validation Loss:  0.7778\n",
      "Validation Accuracy:  0.7322\n",
      "Validation Loss:  0.7797\n",
      "Validation Accuracy:  0.7322\n",
      "Validation Loss:  0.7749\n",
      "Validation Accuracy:  0.7322\n",
      "Validation Loss:  0.7880\n",
      "Validation Accuracy:  0.7322\n",
      "Validation Loss:  0.7757\n",
      "Validation Accuracy:  0.7322\n",
      "Validation Loss:  0.7628\n",
      "TRAINING INDEPENDENT...\n",
      "Validation Accuracy:  0.7432\n",
      "Validation Loss:  0.7809\n",
      "Validation Accuracy:  0.7432\n",
      "Validation Loss:  0.7777\n",
      "Validation Accuracy:  0.7432\n",
      "Validation Loss:  0.7704\n",
      "Validation Accuracy:  0.7486\n",
      "Validation Loss:  0.7951\n",
      "Validation Accuracy:  0.7486\n",
      "Validation Loss:  0.7797\n",
      "Validation Accuracy:  0.7486\n",
      "Validation Loss:  0.7718\n",
      "Validation Accuracy:  0.7486\n",
      "Validation Loss:  0.7607\n",
      "Validation Accuracy:  0.7486\n",
      "Validation Loss:  0.7772\n",
      "TRAINING CLIENT 9\n",
      "Validation Accuracy:  0.7322\n",
      "Validation Loss:  0.7888\n",
      "Validation Accuracy:  0.7322\n",
      "Validation Loss:  0.8389\n",
      "Validation Accuracy:  0.7322\n",
      "Validation Loss:  0.7973\n",
      "Validation Accuracy:  0.7268\n",
      "Validation Loss:  0.7738\n",
      "Validation Accuracy:  0.7322\n",
      "Validation Loss:  0.7901\n",
      "Validation Accuracy:  0.7268\n",
      "Validation Loss:  0.7956\n",
      "Validation Accuracy:  0.7268\n",
      "Validation Loss:  0.7874\n",
      "Validation Accuracy:  0.7268\n",
      "Validation Loss:  0.7640\n",
      "TRAINING INDEPENDENT...\n",
      "Validation Accuracy:  0.7104\n",
      "Validation Loss:  0.8902\n",
      "Validation Accuracy:  0.7104\n",
      "Validation Loss:  0.8636\n",
      "Validation Accuracy:  0.7158\n",
      "Validation Loss:  0.8658\n",
      "Validation Accuracy:  0.7158\n",
      "Validation Loss:  0.8550\n",
      "Validation Accuracy:  0.7158\n",
      "Validation Loss:  0.8511\n",
      "Validation Accuracy:  0.7158\n",
      "Validation Loss:  0.8281\n",
      "Validation Accuracy:  0.7158\n",
      "Validation Loss:  0.8518\n",
      "Validation Accuracy:  0.7158\n",
      "Validation Loss:  0.8672\n",
      "Loss = 1.2632084091504414, Acc = 0.4918032786885246\n",
      "ROUND: 6\n",
      "--------------------------------------------------\n",
      "TRAINING CLIENT 0\n",
      "Validation Accuracy:  0.7322\n",
      "Validation Loss:  0.7886\n",
      "Validation Accuracy:  0.7322\n",
      "Validation Loss:  0.7754\n",
      "Validation Accuracy:  0.7322\n",
      "Validation Loss:  0.7311\n",
      "Validation Accuracy:  0.7322\n",
      "Validation Loss:  0.7404\n",
      "Validation Accuracy:  0.7322\n",
      "Validation Loss:  0.7325\n",
      "Validation Accuracy:  0.7322\n",
      "Validation Loss:  0.7422\n",
      "Validation Accuracy:  0.7322\n",
      "Validation Loss:  0.7307\n",
      "Validation Accuracy:  0.7322\n",
      "Validation Loss:  0.7449\n",
      "TRAINING INDEPENDENT...\n",
      "Validation Accuracy:  0.7322\n",
      "Validation Loss:  0.8039\n",
      "Validation Accuracy:  0.7322\n",
      "Validation Loss:  0.7842\n",
      "Validation Accuracy:  0.7322\n",
      "Validation Loss:  0.7749\n",
      "Validation Accuracy:  0.7322\n",
      "Validation Loss:  0.7731\n",
      "Validation Accuracy:  0.7377\n",
      "Validation Loss:  0.8066\n",
      "Validation Accuracy:  0.7377\n",
      "Validation Loss:  0.7818\n",
      "Validation Accuracy:  0.7322\n",
      "Validation Loss:  0.7738\n",
      "Validation Accuracy:  0.7322\n",
      "Validation Loss:  0.7921\n",
      "TRAINING CLIENT 1\n",
      "Validation Accuracy:  0.7322\n",
      "Validation Loss:  0.7817\n",
      "Validation Accuracy:  0.7322\n",
      "Validation Loss:  0.7475\n",
      "Validation Accuracy:  0.7322\n",
      "Validation Loss:  0.7447\n",
      "Validation Accuracy:  0.7322\n",
      "Validation Loss:  0.7292\n",
      "Validation Accuracy:  0.7322\n",
      "Validation Loss:  0.7626\n",
      "Validation Accuracy:  0.7322\n",
      "Validation Loss:  0.7622\n",
      "Validation Accuracy:  0.7322\n",
      "Validation Loss:  0.7485\n",
      "Validation Accuracy:  0.7322\n",
      "Validation Loss:  0.7515\n",
      "TRAINING INDEPENDENT...\n",
      "Validation Accuracy:  0.7268\n",
      "Validation Loss:  0.8178\n",
      "Validation Accuracy:  0.7268\n",
      "Validation Loss:  0.8104\n",
      "Validation Accuracy:  0.7268\n",
      "Validation Loss:  0.7894\n",
      "Validation Accuracy:  0.7268\n",
      "Validation Loss:  0.8163\n",
      "Validation Accuracy:  0.7213\n",
      "Validation Loss:  0.8082\n",
      "Validation Accuracy:  0.7158\n",
      "Validation Loss:  0.7947\n",
      "Validation Accuracy:  0.7158\n",
      "Validation Loss:  0.8008\n",
      "Validation Accuracy:  0.7158\n",
      "Validation Loss:  0.7784\n",
      "TRAINING CLIENT 2\n",
      "Validation Accuracy:  0.7322\n",
      "Validation Loss:  0.7713\n",
      "Validation Accuracy:  0.7322\n",
      "Validation Loss:  0.7437\n",
      "Validation Accuracy:  0.7322\n",
      "Validation Loss:  0.7800\n",
      "Validation Accuracy:  0.7322\n",
      "Validation Loss:  0.7610\n",
      "Validation Accuracy:  0.7322\n",
      "Validation Loss:  0.7695\n",
      "Validation Accuracy:  0.7322\n",
      "Validation Loss:  0.7457\n",
      "Validation Accuracy:  0.7322\n",
      "Validation Loss:  0.7620\n",
      "Validation Accuracy:  0.7322\n",
      "Validation Loss:  0.7448\n",
      "TRAINING INDEPENDENT...\n",
      "Validation Accuracy:  0.7049\n",
      "Validation Loss:  0.8418\n",
      "Validation Accuracy:  0.7049\n",
      "Validation Loss:  0.8220\n",
      "Validation Accuracy:  0.7049\n",
      "Validation Loss:  0.8181\n",
      "Validation Accuracy:  0.7049\n",
      "Validation Loss:  0.7944\n",
      "Validation Accuracy:  0.7049\n",
      "Validation Loss:  0.8030\n",
      "Validation Accuracy:  0.6995\n",
      "Validation Loss:  0.8130\n",
      "Validation Accuracy:  0.6995\n",
      "Validation Loss:  0.8057\n",
      "Validation Accuracy:  0.7158\n",
      "Validation Loss:  0.8350\n",
      "TRAINING CLIENT 3\n",
      "Validation Accuracy:  0.7322\n",
      "Validation Loss:  0.7601\n",
      "Validation Accuracy:  0.7322\n",
      "Validation Loss:  0.7524\n",
      "Validation Accuracy:  0.7322\n",
      "Validation Loss:  0.7736\n",
      "Validation Accuracy:  0.7322\n",
      "Validation Loss:  0.7423\n",
      "Validation Accuracy:  0.7322\n",
      "Validation Loss:  0.7644\n",
      "Validation Accuracy:  0.7322\n",
      "Validation Loss:  0.7657\n",
      "Validation Accuracy:  0.7322\n",
      "Validation Loss:  0.7641\n",
      "Validation Accuracy:  0.7322\n",
      "Validation Loss:  0.7423\n",
      "TRAINING INDEPENDENT...\n",
      "Validation Accuracy:  0.7158\n",
      "Validation Loss:  0.8359\n",
      "Validation Accuracy:  0.7104\n",
      "Validation Loss:  0.8270\n",
      "Validation Accuracy:  0.7104\n",
      "Validation Loss:  0.8187\n",
      "Validation Accuracy:  0.7158\n",
      "Validation Loss:  0.8247\n",
      "Validation Accuracy:  0.7104\n",
      "Validation Loss:  0.7966\n",
      "Validation Accuracy:  0.7158\n",
      "Validation Loss:  0.8016\n",
      "Validation Accuracy:  0.7158\n",
      "Validation Loss:  0.8257\n",
      "Validation Accuracy:  0.7158\n",
      "Validation Loss:  0.8224\n",
      "TRAINING CLIENT 4\n",
      "Validation Accuracy:  0.7322\n",
      "Validation Loss:  0.7643\n",
      "Validation Accuracy:  0.7322\n",
      "Validation Loss:  0.7491\n",
      "Validation Accuracy:  0.7322\n",
      "Validation Loss:  0.7616\n",
      "Validation Accuracy:  0.7322\n",
      "Validation Loss:  0.7447\n",
      "Validation Accuracy:  0.7322\n",
      "Validation Loss:  0.7565\n",
      "Validation Accuracy:  0.7322\n",
      "Validation Loss:  0.7705\n",
      "Validation Accuracy:  0.7322\n",
      "Validation Loss:  0.7602\n",
      "Validation Accuracy:  0.7322\n",
      "Validation Loss:  0.7408\n",
      "TRAINING INDEPENDENT...\n",
      "Validation Accuracy:  0.7213\n",
      "Validation Loss:  0.8141\n",
      "Validation Accuracy:  0.7213\n",
      "Validation Loss:  0.8191\n",
      "Validation Accuracy:  0.7213\n",
      "Validation Loss:  0.7934\n",
      "Validation Accuracy:  0.7213\n",
      "Validation Loss:  0.8014\n",
      "Validation Accuracy:  0.7213\n",
      "Validation Loss:  0.7903\n",
      "Validation Accuracy:  0.7213\n",
      "Validation Loss:  0.7982\n",
      "Validation Accuracy:  0.7213\n",
      "Validation Loss:  0.7977\n",
      "Validation Accuracy:  0.7213\n",
      "Validation Loss:  0.8169\n",
      "TRAINING CLIENT 5\n",
      "Validation Accuracy:  0.7322\n",
      "Validation Loss:  0.7822\n",
      "Validation Accuracy:  0.7322\n",
      "Validation Loss:  0.7527\n",
      "Validation Accuracy:  0.7322\n",
      "Validation Loss:  0.7457\n",
      "Validation Accuracy:  0.7322\n",
      "Validation Loss:  0.7534\n",
      "Validation Accuracy:  0.7322\n",
      "Validation Loss:  0.7394\n",
      "Validation Accuracy:  0.7322\n",
      "Validation Loss:  0.7794\n",
      "Validation Accuracy:  0.7322\n",
      "Validation Loss:  0.7702\n",
      "Validation Accuracy:  0.7322\n",
      "Validation Loss:  0.7515\n",
      "TRAINING INDEPENDENT...\n",
      "Validation Accuracy:  0.7213\n",
      "Validation Loss:  0.8356\n",
      "Validation Accuracy:  0.7268\n",
      "Validation Loss:  0.8091\n",
      "Validation Accuracy:  0.7322\n",
      "Validation Loss:  0.7981\n",
      "Validation Accuracy:  0.7322\n",
      "Validation Loss:  0.8238\n",
      "Validation Accuracy:  0.7322\n",
      "Validation Loss:  0.8156\n",
      "Validation Accuracy:  0.7322\n",
      "Validation Loss:  0.7773\n",
      "Validation Accuracy:  0.7268\n",
      "Validation Loss:  0.7871\n",
      "Validation Accuracy:  0.7322\n",
      "Validation Loss:  0.8121\n",
      "TRAINING CLIENT 6\n",
      "Validation Accuracy:  0.7268\n",
      "Validation Loss:  0.7695\n",
      "Validation Accuracy:  0.7322\n",
      "Validation Loss:  0.7456\n",
      "Validation Accuracy:  0.7322\n",
      "Validation Loss:  0.7786\n",
      "Validation Accuracy:  0.7322\n",
      "Validation Loss:  0.7567\n",
      "Validation Accuracy:  0.7322\n",
      "Validation Loss:  0.7418\n",
      "Validation Accuracy:  0.7322\n",
      "Validation Loss:  0.7469\n",
      "Validation Accuracy:  0.7322\n",
      "Validation Loss:  0.7276\n",
      "Validation Accuracy:  0.7322\n",
      "Validation Loss:  0.7627\n",
      "TRAINING INDEPENDENT...\n",
      "Validation Accuracy:  0.7322\n",
      "Validation Loss:  0.7794\n",
      "Validation Accuracy:  0.7322\n",
      "Validation Loss:  0.7850\n",
      "Validation Accuracy:  0.7322\n",
      "Validation Loss:  0.7716\n",
      "Validation Accuracy:  0.7322\n",
      "Validation Loss:  0.7925\n",
      "Validation Accuracy:  0.7322\n",
      "Validation Loss:  0.7606\n",
      "Validation Accuracy:  0.7322\n",
      "Validation Loss:  0.7734\n",
      "Validation Accuracy:  0.7322\n",
      "Validation Loss:  0.7505\n",
      "Validation Accuracy:  0.7322\n",
      "Validation Loss:  0.7775\n",
      "TRAINING CLIENT 7\n",
      "Validation Accuracy:  0.7322\n",
      "Validation Loss:  0.7820\n",
      "Validation Accuracy:  0.7322\n",
      "Validation Loss:  0.7644\n",
      "Validation Accuracy:  0.7322\n",
      "Validation Loss:  0.7565\n",
      "Validation Accuracy:  0.7322\n",
      "Validation Loss:  0.7533\n",
      "Validation Accuracy:  0.7322\n",
      "Validation Loss:  0.7441\n",
      "Validation Accuracy:  0.7322\n",
      "Validation Loss:  0.7420\n",
      "Validation Accuracy:  0.7322\n",
      "Validation Loss:  0.7551\n",
      "Validation Accuracy:  0.7322\n",
      "Validation Loss:  0.7301\n",
      "TRAINING INDEPENDENT...\n",
      "Validation Accuracy:  0.7541\n",
      "Validation Loss:  0.7714\n",
      "Validation Accuracy:  0.7486\n",
      "Validation Loss:  0.7416\n",
      "Validation Accuracy:  0.7541\n",
      "Validation Loss:  0.7442\n",
      "Validation Accuracy:  0.7596\n",
      "Validation Loss:  0.7552\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[42], line 41\u001b[0m\n\u001b[0;32m     39\u001b[0m     validate(models_fed[client], val_loader)\n\u001b[0;32m     40\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTRAINING INDEPENDENT...\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m---> 41\u001b[0m \u001b[43mtrain_loop\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m     42\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmodels_ind\u001b[49m\u001b[43m[\u001b[49m\u001b[43mclient\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     43\u001b[0m \u001b[43m    \u001b[49m\u001b[43mloaders\u001b[49m\u001b[43m[\u001b[49m\u001b[43mclient\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     44\u001b[0m \u001b[43m    \u001b[49m\u001b[43mval_loader\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     45\u001b[0m \u001b[43m    \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mEPOCHS\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     46\u001b[0m \u001b[43m    \u001b[49m\u001b[43mlr\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mLEARNING_RATE\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     47\u001b[0m \u001b[43m    \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m     48\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     49\u001b[0m losses_clients[client]\u001b[38;5;241m.\u001b[39mappend(models_ind[client]\u001b[38;5;241m.\u001b[39mget_loss(val_loader))\n\u001b[0;32m     50\u001b[0m accuracies_clients[client]\u001b[38;5;241m.\u001b[39mappend(models_ind[client]\u001b[38;5;241m.\u001b[39mget_accuracy(val_loader))\n",
      "File \u001b[1;32mc:\\Users\\diego\\OneDrive\\Documentos\\GitHub\\Diabetic-Retinopathy\\model.py:179\u001b[0m, in \u001b[0;36mtrain_loop\u001b[1;34m(model, train_loader, val_loader, epochs, lr, verbose)\u001b[0m\n\u001b[0;32m    177\u001b[0m optimizer \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39moptim\u001b[38;5;241m.\u001b[39mSGD(model\u001b[38;5;241m.\u001b[39mparameters(), lr\u001b[38;5;241m=\u001b[39mlr)\n\u001b[0;32m    178\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m epoch \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(epochs):\n\u001b[1;32m--> 179\u001b[0m     \u001b[43mtrain_step\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mverbose\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    180\u001b[0m     validate(model, val_loader)\n\u001b[0;32m    181\u001b[0m     model\u001b[38;5;241m.\u001b[39mepochs_trained \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n",
      "File \u001b[1;32mc:\\Users\\diego\\OneDrive\\Documentos\\GitHub\\Diabetic-Retinopathy\\model.py:125\u001b[0m, in \u001b[0;36mtrain_step\u001b[1;34m(model, data_loader, optimizer, update_every, verbose)\u001b[0m\n\u001b[0;32m    122\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mstep()\n\u001b[0;32m    124\u001b[0m \u001b[38;5;66;03m# metrics\u001b[39;00m\n\u001b[1;32m--> 125\u001b[0m loss \u001b[38;5;241m=\u001b[39m \u001b[43mloss\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mitem\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    126\u001b[0m y_pred \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39margmax(outputs, dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[0;32m    127\u001b[0m accuracy \u001b[38;5;241m=\u001b[39m accuracy_fn(y_pred, y_true)\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "m_clients = int(max(1, K_CLIENTS * C))\n",
    "loss = global_model.get_loss(val_loader)\n",
    "acc = global_model.get_accuracy(val_loader)\n",
    "print(f\"Loss = {loss}, Acc = {acc}\")\n",
    "for r in range(rounds):\n",
    "    dash = \"-\"\n",
    "    print(f\"ROUND: {r}\\n{dash * 50}\")\n",
    "    selected_clients = np.random.choice(clients, m_clients, replace=False)\n",
    "    selected_clients.sort()\n",
    "    x = copy.deepcopy(global_model)\n",
    "\n",
    "    for client in selected_clients:\n",
    "        print(f\"TRAINING CLIENT {client}\")\n",
    "\n",
    "        # Fed part\n",
    "        ## Dispatching the global model to the clients\n",
    "        for old, new in zip(models_fed[client].parameters(), global_model.parameters()):\n",
    "            old.data = new.data.clone()\n",
    "        ## Training the client model\n",
    "\n",
    "        # optimizer = torch.optim.SGD(\n",
    "        #   models_fed[client].parameters(), lr=models_fed[client].lr\n",
    "        # )\n",
    "        optimizer = ScaffoldOptimizer(\n",
    "            models_fed[client].parameters(), lr=models_fed[client].lr, weight_decay=1e-7\n",
    "        )\n",
    "        # lr_step = StepLR(optimizer, step_size=10, gamma=0.1)\n",
    "\n",
    "        for epoch in range(EPOCHS):\n",
    "            models_fed[client].train()\n",
    "            for i, batch in enumerate(loaders[client]):\n",
    "                inputs, y_true = batch[\"image\"].to(device), batch[\"labels\"].to(device)\n",
    "                optimizer.zero_grad()\n",
    "                outputs = models_fed[client](inputs)\n",
    "                loss = loss_fn(outputs, y_true)\n",
    "                loss.backward()\n",
    "                optimizer.step(global_model.control, models_fed[client].control)\n",
    "            # lr_step.step()\n",
    "            validate(models_fed[client], val_loader)\n",
    "        print(\"TRAINING INDEPENDENT...\")\n",
    "        train_loop(\n",
    "            models_ind[client],\n",
    "            loaders[client],\n",
    "            val_loader,\n",
    "            epochs=EPOCHS,\n",
    "            lr=LEARNING_RATE,\n",
    "            verbose=False,\n",
    "        )\n",
    "        losses_clients[client].append(models_ind[client].get_loss(val_loader))\n",
    "        accuracies_clients[client].append(models_ind[client].get_accuracy(val_loader))\n",
    "        ## control variables update\n",
    "        temp = {}\n",
    "        for key, layer in models_fed[client].named_parameters():\n",
    "            temp[key] = layer.data.clone()\n",
    "\n",
    "        for key, layer in x.named_parameters():\n",
    "            local_steps = EPOCHS * len(datasets[client])\n",
    "            models_fed[client].control[key] = (\n",
    "                models_fed[client].control[key]\n",
    "                - global_model.control[key]\n",
    "                + (layer.data - temp[key]) / (local_steps * models_fed[client].lr)\n",
    "            )\n",
    "            models_fed[client].delta_y[key] = temp[key] - layer.data\n",
    "            models_fed[client].delta_control[key] = (\n",
    "                models_fed[client].control[key] - x.control[key]\n",
    "            )\n",
    "\n",
    "    s = sum([len(datasets[i]) for i in selected_clients])\n",
    "    x = {}\n",
    "    c = {}\n",
    "\n",
    "    for key, layer in models_fed[0].named_parameters():\n",
    "        x[key] = torch.zeros_like(layer.data)\n",
    "        c[key] = torch.zeros_like(layer.data)\n",
    "\n",
    "    for client in selected_clients:\n",
    "        for key, layer in models_fed[client].named_parameters():\n",
    "            x[key] += models_fed[client].delta_y[key] / len(\n",
    "                selected_clients\n",
    "            )  # averaging\n",
    "            c[key] += models_fed[client].delta_control[key] / len(\n",
    "                selected_clients\n",
    "            )  # averaging\n",
    "\n",
    "    # update x and c\n",
    "    for key, layer in global_model.named_parameters():\n",
    "        layer.data += 1 * x[key].data  # lr=1\n",
    "        global_model.control[key].data += c[key].data * (\n",
    "            len(selected_clients) / len(clients)\n",
    "        )\n",
    "    loss = global_model.get_loss(val_loader)\n",
    "    losses.append(loss)\n",
    "    acc = global_model.get_accuracy(val_loader)\n",
    "    accuracies.append(acc)\n",
    "    print(f\"Loss = {loss}, Acc = {acc}\")\n",
    "\n",
    "    save_plots()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "ax = plot_losses()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "ax = plot_accuracies()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
