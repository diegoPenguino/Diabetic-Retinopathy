{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import copy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "from src.constants import csv_file, directory, INPUT_SHAPE, YEAR, ext\n",
    "\n",
    "from src.utils import (\n",
    "    get_dataloader,\n",
    "    sample_iid,\n",
    "    split_val,\n",
    ")\n",
    "\n",
    "from src.model import Model_Retinopathy\n",
    "from src.server_scaffold import Server_Scaffold\n",
    "from src.server_fedavg import Server_FedAVG\n",
    "\n",
    "from src.constants import EPOCHS, BATCH_SIZE, LEARNING_RATE, UPDATES\n",
    "from src.constants import K_CLIENTS, C, rounds, clients\n",
    "from src.constants import optimizer_fn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DATA STUFF\n",
    "df = pd.read_csv(csv_file)\n",
    "df, val_df = split_val(df, 0.05)\n",
    "df = sample_iid(df, 0.3).reset_index(drop=True)\n",
    "_, val_loader = get_dataloader(val_df, ext, directory, BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# server_fedavg = Server_FedAVG(K_CLIENTS, optimizer_fn, df, val_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# server_fedavg.train_loop(rounds, EPOCHS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0 MB\n",
      "394.33447265625 MB\n"
     ]
    }
   ],
   "source": [
    "gpu_memory = torch.cuda.memory_allocated()\n",
    "print(gpu_memory / (1024**2), \"MB\")\n",
    "server_scaffold = Server_Scaffold(K_CLIENTS, optimizer_fn, df, val_loader)\n",
    "\"\"\" for key, layer in server_scaffold.model.named_parameters():\n",
    "    print(key, layer) \"\"\"\n",
    "print((torch.cuda.memory_allocated() - gpu_memory) / (1024**2), \"MB\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "server_scaffold.train_loop(rounds, EPOCHS)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
